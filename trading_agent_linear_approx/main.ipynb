{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from stock_market_env import StockMarketEnv\n",
    "from trading_agent import LinearQTradingAgent\n",
    "\n",
    "# Simulated stock prices\n",
    "prices = np.random.randn(500) + 100  # Random walk stock prices\n",
    "price_changes_pct = (prices[1:] / prices[:-1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100.9805070101',\n",
       " '99.2774862212',\n",
       " '99.2756595406',\n",
       " '99.9227620151',\n",
       " '100.7791236669',\n",
       " '98.3064883226',\n",
       " '100.6972445875',\n",
       " '101.9630835699',\n",
       " '100.6207829189',\n",
       " '99.8995725134']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.random.default_rng().normal(100, 1, 10)\n",
    "[format(x, '.10f') for x in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-68757643700000002501143666735710208.0000000000\n"
     ]
    }
   ],
   "source": [
    "print(format(-6.87576437e+34, '.10f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.2, 2: 1.1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {0: 1.4, 1: 1.2, 2: 1.1}\n",
    "x.pop(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0.0, Q-value: 0.0, Action: 0, State: [-6.12606592e-03  1.00039333e+02  8.73925506e-01], Reward: 0, Next state: [6.85298346e-03 9.99626496e+01 8.39448274e-01], Next Q-values: [np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Error: 0.0, Weights: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], State: [-6.12606592e-03  1.00039333e+02  8.73925506e-01]\n",
      "Target: 0.0, Q-value: 0.0, Action: 0, State: [6.85298346e-03 9.99626496e+01 8.39448274e-01], Reward: 0, Next state: [-4.19336283e-03  9.96649556e+01  5.33930847e-01], Next Q-values: [np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Error: 0.0, Weights: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], State: [6.85298346e-03 9.99626496e+01 8.39448274e-01]\n",
      "Target: 0.0, Q-value: 0.0, Action: 0, State: [-4.19336283e-03  9.96649556e+01  5.33930847e-01], Reward: 0, Next state: [2.99104254e-03 9.99359727e+01 2.55752827e-01], Next Q-values: [np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Error: 0.0, Weights: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], State: [-4.19336283e-03  9.96649556e+01  5.33930847e-01]\n",
      "Target: -1.0, Q-value: 0.0, Action: 1, State: [2.99104254e-03 9.99359727e+01 2.55752827e-01], Reward: -1, Next state: [4.60134881e-03 1.00017438e+02 3.50566521e-01], Next Q-values: [np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Error: -1.0, Weights: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], State: [2.99104254e-03 9.99359727e+01 2.55752827e-01]\n",
      "Target: 0.0, Q-value: 0.0, Action: 2, State: [4.60134881e-03 1.00017438e+02 3.50566521e-01], Reward: 0, Next state: [-3.58271298e-03  1.00149543e+02  2.43502452e-01], Next Q-values: [np.float64(0.0), np.float64(-1000.8604234751677), np.float64(0.0)]\n",
      "Error: 0.0, Weights: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.99104254e-04 -9.99359727e+00 -2.55752827e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]], State: [4.60134881e-03 1.00017438e+02 3.50566521e-01]\n",
      "Target: -1.0, Q-value: -1000.8604234751677, Action: 1, State: [-3.58271298e-03  1.00149543e+02  2.43502452e-01], Reward: -1, Next state: [-3.52943094e-03  1.00074545e+02  2.73962408e-01], Next Q-values: [np.float64(0.0), np.float64(-1000.111706035698), np.float64(0.0)]\n",
      "Error: 999.8604234751677, Weights: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.99104254e-04 -9.99359727e+00 -2.55752827e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]], State: [-3.58271298e-03  1.00149543e+02  2.43502452e-01]\n",
      "Target: 897996.2915632362, Q-value: 0.0, Action: 2, State: [-3.52943094e-03  1.00074545e+02  2.73962408e-01], Reward: 0, Next state: [-1.72219969e-02  9.97397596e+01  8.51124925e-01], Next Q-values: [np.float64(0.0), np.float64(997773.6572924847), np.float64(0.0)]\n",
      "Error: 897996.2915632362, Weights: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.58520396e-01  1.00035628e+04  2.43212712e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]], State: [-3.52943094e-03  1.00074545e+02  2.73962408e-01]\n",
      "Target: 803854778.8469409, Q-value: 0.0, Action: 0, State: [-1.72219969e-02  9.97397596e+01  8.51124925e-01], Reward: -186.91874714901928, Next state: [2.07396589e-03 9.93859797e+01 9.94714158e-01], Next Q-values: [np.float64(0.0), np.float64(994238.083133293), np.float64(893172184.1840978)]\n",
      "Error: 803854778.8469409, Weights: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.58520396e-01  1.00035628e+04  2.43212712e+01]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [-1.72219969e-02  9.97397596e+01  8.51124925e-01]\n",
      "Target: 718166450961.0005, Q-value: 796907890833.6636, Action: 0, State: [2.07396589e-03 9.93859797e+01 9.94714158e-01], Reward: 0, Next state: [2.92966698e-02 9.95161009e+01 1.16436170e+00], Next Q-values: [np.float64(797962723290.0005), np.float64(995543.8747359595), np.float64(894345703.5235435)]\n",
      "Error: -78741439872.66309, Weights: [[-1.38439845e+06  8.01762824e+09  6.84180839e+07]\n",
      " [-3.58520396e-01  1.00035628e+04  2.43212712e+01]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [2.07396589e-03 9.93859797e+01 9.94714158e-01]\n",
      "Target: 804344808.993377, Q-value: 995543.8747359595, Action: 1, State: [2.92966698e-02 9.95161009e+01 1.16436170e+00], Reward: -1, Next state: [-1.34454847e-02  9.94461653e+01  1.13288041e+00], Next Q-values: [np.float64(-77036004911606.83), np.float64(994843.5194756101), np.float64(893716455.5481966)]\n",
      "Error: 803349265.118641, Weights: [[-1.77151045e+07 -7.74561886e+11 -7.76410442e+09]\n",
      " [-3.58520396e-01  1.00035628e+04  2.43212712e+01]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [2.92966698e-02 9.95161009e+01 1.16436170e+00]\n",
      "Target: 714913062861.9642, Q-value: 795141099145.779, Action: 1, State: [-1.34454847e-02  9.94461653e+01  1.13288041e+00], Reward: -1, Next state: [-4.99984594e-03  9.93471202e+01  1.11745711e+00], Next Q-values: [np.float64(-76959168761004.22), np.float64(794347847625.5157), np.float64(892825989.1726638)]\n",
      "Error: -80228036283.81482, Weights: [[-1.77151045e+07 -7.74561886e+11 -7.76410442e+09]\n",
      " [ 2.35354546e+06  7.99462865e+09  9.35389363e+07]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [-1.34454847e-02  9.94461653e+01  1.13288041e+00]\n",
      "Target: 802555979.9245334, Q-value: -78478622983225.12, Action: 1, State: [-4.99984594e-03  9.93471202e+01  1.11745711e+00], Reward: -1, Next state: [-1.84887329e-02  9.92246173e+01  1.27051076e+00], Next Q-values: [np.float64(-76865470804659.19), np.float64(-78383243287572.14), np.float64(891728867.693926)]\n",
      "Error: 78479425539205.05, Weights: [[-1.77151045e+07 -7.74561886e+11 -7.76410442e+09]\n",
      " [ 1.10224029e+08 -7.89842427e+11 -8.99533810e+09]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [-4.99984594e-03  9.93471202e+01  1.11745711e+00]\n",
      "Target: 6.986100487069337e+16, Q-value: -76865470804659.19, Action: 0, State: [-1.84887329e-02  9.92246173e+01  1.27051076e+00], Reward: 0, Next state: [2.99883861e-02 9.96461238e+01 1.24444178e+00], Next Q-values: [np.float64(-77191752135966.84), np.float64(7.762333874521485e+16), np.float64(895516145.3993737)]\n",
      "Error: 6.9937870341498024e+16, Weights: [[-1.77151045e+07 -7.74561886e+11 -7.76410442e+09]\n",
      " [-3.91282797e+10  7.78880650e+14  8.76074385e+12]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [-1.84887329e-02  9.92246173e+01  1.27051076e+00]\n",
      "Target: 6.187548705212965e+19, Q-value: 6.9160986438239945e+19, Action: 0, State: [2.99883861e-02 9.96461238e+01 1.24444178e+00], Reward: 0, Next state: [-2.16423019e-02  9.90570087e+01  1.06071481e+00], Next Q-values: [np.float64(6.875054116903294e+19), np.float64(7.716288083048958e+16), np.float64(890217466.4288168)]\n",
      "Error: -7.285499386110296e+18, Weights: [[-1.29306278e+14  6.93955068e+17  8.88567391e+15]\n",
      " [-3.91282797e+10  7.78880650e+14  8.76074385e+12]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [2.99883861e-02 9.96461238e+01 1.24444178e+00]\n",
      "Target: 6.9211292989249944e+16, Q-value: 7.716288083048958e+16, Action: 1, State: [-2.16423019e-02  9.90570087e+01  1.06071481e+00], Reward: -1, Next state: [-9.31318527e-04  9.87216885e+01  1.03001945e+00], Next Q-values: [np.float64(-7.099332200030728e+21), np.float64(7.690143665472216e+16), np.float64(887203296.6579684)]\n",
      "Error: -7951587841239640.0, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [-3.91282797e+10  7.78880650e+14  8.76074385e+12]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [-2.16423019e-02  9.90570087e+01  1.06071481e+00]\n",
      "Target: 797786653.3756878, Q-value: -7.699884850604657e+18, Action: 1, State: [-9.31318527e-04  9.87216885e+01  1.03001945e+00], Reward: -1, Next state: [7.61657024e-03 9.86356968e+01 9.93423024e-01], Next Q-values: [np.float64(-7.093116455237082e+21), np.float64(-7.693147910739232e+18), np.float64(886429615.9729865)]\n",
      "Error: 7.699884851402444e+18, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [ 1.71699381e+13 -7.79871700e+16 -8.34675956e+14]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [-9.31318527e-04  9.87216885e+01  1.03001945e+00]\n",
      "Target: 6.76134043994108e+21, Q-value: 886429615.9729865, Action: 2, State: [7.61657024e-03 9.86356968e+01 9.93423024e-01], Reward: 0, Next state: [3.60328036e-04 9.89241079e+01 8.10873900e-01], Next Q-values: [np.float64(-7.113690097924244e+21), np.float64(7.512600488823421e+21), np.float64(889016978.7157941)]\n",
      "Error: 6.761340439940194e+21, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [-6.99934604e+14  7.59365762e+19  7.92268442e+17]\n",
      " [-3.16941589e+02  8.98665703e+06  2.46017226e+04]], State: [7.61657024e-03 9.86356968e+01 9.93423024e-01]\n",
      "Target: 5.928364051349093e+24, Q-value: 6.597887645168244e+24, Action: 2, State: [3.60328036e-04 9.89241079e+01 8.10873900e-01], Reward: 0, Next state: [6.91858345e-03 9.87647092e+01 5.33867449e-01], Next Q-values: [np.float64(-7.101980280901625e+21), np.float64(7.50027683154943e+21), np.float64(6.587071168165659e+24)]\n",
      "Error: -6.695235938191514e+23, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [-6.99934604e+14  7.59365762e+19  7.92268442e+17]\n",
      " [ 5.14982244e+18  6.66909526e+22  6.71687127e+20]], State: [3.60328036e-04 9.89241079e+01 8.10873900e-01]\n",
      "Target: 6.747955487940535e+21, Q-value: -6.475805743163764e+26, Action: 2, State: [6.91858345e-03 9.87647092e+01 5.33867449e-01], Reward: 0, Next state: [-1.55183643e-02  9.87307668e+01  5.70405708e-01], Next Q-values: [np.float64(-7.099572016691716e+21), np.float64(7.497728319933928e+21), np.float64(-6.473599887730626e+26)]\n",
      "Error: 6.475873222718644e+26, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [-6.99934604e+14  7.59365762e+19  7.92268442e+17]\n",
      " [-1.89749897e+19 -6.55651147e+24 -5.36182336e+22]], State: [6.91858345e-03 9.87647092e+01 5.33867449e-01]\n",
      "Target: 5.693373710386195e+29, Q-value: 7.497728319933928e+21, Action: 1, State: [-1.55183643e-02  9.87307668e+01  5.70405708e-01], Reward: -1, Next state: [1.48053073e-02 9.90055094e+01 5.53519105e-01], Next Q-values: [np.float64(-7.119312405408318e+21), np.float64(7.518577936609776e+21), np.float64(6.325970789317994e+29)]\n",
      "Error: 5.693373635408912e+29, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [-6.99934604e+14  7.59365762e+19  7.92268442e+17]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [-1.55183643e-02  9.87307668e+01  5.70405708e-01]\n",
      "Target: 5.039830908909207e+32, Q-value: -7.119312405408318e+21, Action: 0, State: [1.48053073e-02 9.90055094e+01 5.53519105e-01], Reward: 300.5142937943262, Next state: [2.42624051e-02 9.96136649e+01 1.28472163e+00], Next Q-values: [np.float64(-7.163697389558478e+21), np.float64(5.59981212101023e+32), np.float64(6.365080239057038e+29)]\n",
      "Error: 5.0398309089803995e+32, Weights: [[-2.19773431e+16 -7.19032223e+19 -8.97752310e+17]\n",
      " [-8.83518461e+26  5.62111145e+30  3.24753282e+28]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [1.48053073e-02 9.90055094e+01 5.53519105e-01]\n",
      "Target: 4.4670441595789585e+35, Q-value: 4.970791835015549e+35, Action: 0, State: [2.42624051e-02 9.96136649e+01 1.28472163e+00], Reward: 0, Next state: [-3.67942528e-02  9.94645686e+01  1.39402903e+00], Next Q-values: [np.float64(4.9633823995321764e+35), np.float64(5.5914672899155225e+32), np.float64(6.355591457112201e+29)]\n",
      "Error: -5.037476754365907e+34, Weights: [[ 7.46162452e+29  4.98971027e+33  2.78964269e+31]\n",
      " [-8.83518461e+26  5.62111145e+30  3.24753282e+28]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [2.42624051e-02 9.96136649e+01 1.28472163e+00]\n",
      "Target: 5.036049455168703e+32, Q-value: -4.942415091357008e+37, Action: 0, State: [-3.67942528e-02  9.94645686e+01  1.39402903e+00], Reward: 0, Next state: [1.83131832e-02 9.95381952e+01 1.40963099e+00], Next Q-values: [np.float64(-4.94608367328139e+37), np.float64(5.595610505743003e+32), np.float64(6.36030133239387e+29)]\n",
      "Error: 4.94246545185156e+37, Weights: [[-1.21475139e+32 -4.96811811e+35 -6.44385890e+33]\n",
      " [-8.83518461e+26  5.62111145e+30  3.24753282e+28]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [-3.67942528e-02  9.94645686e+01  1.39402903e+00]\n",
      "Target: 4.418277356477148e+40, Q-value: 4.889324419750318e+40, Action: 0, State: [1.83131832e-02 9.95381952e+01 1.40963099e+00], Reward: 0, Next state: [1.23567370e-03 9.99457015e+01 1.20561240e+00], Next Q-values: [np.float64(4.909197062752386e+40), np.float64(5.618450779768789e+32), np.float64(6.386267710744517e+29)]\n",
      "Error: -4.7104706327317007e+39, Weights: [[-1.81975798e+35  4.91103382e+38  6.88349644e+36]\n",
      " [-8.83518461e+26  5.62111145e+30  3.24753282e+28]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [1.83131832e-02 9.95381952e+01 1.40963099e+00]\n",
      "Target: 5.047089875101253e+32, Q-value: 5.618450779768789e+32, Action: 1, State: [1.23567370e-03 9.99457015e+01 1.20561240e+00], Reward: -1, Next state: [-1.52793377e-02  9.97569099e+01  1.32538153e+00], Next Q-values: [np.float64(-4.629199492357491e+42), np.float64(5.607877639001392e+32), np.float64(6.374246483457117e+29)]\n",
      "Error: -5.7136090466753605e+31, Weights: [[-8.80834698e+36 -4.63960712e+40 -6.57119042e+38]\n",
      " [-8.83518461e+26  5.62111145e+30  3.24753282e+28]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [1.23567370e-03 9.99457015e+01 1.20561240e+00]\n",
      "Target: 5.725732816350622e+29, Q-value: 6.374246483457117e+29, Action: 2, State: [-1.52793377e-02  9.97569099e+01  1.32538153e+00], Reward: 0, Next state: [2.43690483e-02 9.95656404e+01 1.03428463e+00], Next Q-values: [np.float64(-4.620134400090144e+42), np.float64(-5.630444666635665e+34), np.float64(6.361925351500691e+29)]\n",
      "Error: -6.485136671064945e+28, Weights: [[-8.80834698e+36 -4.63960712e+40 -6.57119042e+38]\n",
      " [-7.94367491e+27 -5.65429553e+32 -6.85592257e+30]\n",
      " [ 4.48019718e+23  6.38932085e+27  3.45189609e+25]], State: [-1.52793377e-02  9.97569099e+01  1.32538153e+00]\n",
      "Target: -5.770142665308075e+31, Q-value: -5.630444666635665e+34, Action: 1, State: [2.43690483e-02 9.95656404e+01 1.03428463e+00], Reward: -1, Next state: [-2.24406523e-03  1.00079175e+02  8.40251991e-01], Next Q-values: [np.float64(-4.6438326579493534e+42), np.float64(-5.659348390625126e+34), np.float64(-6.411269628120083e+31)]\n",
      "Error: 5.624674523970357e+34, Weights: [[-8.80834698e+36 -4.63960712e+40 -6.57119042e+38]\n",
      " [-7.94367491e+27 -5.65429553e+32 -6.85592257e+30]\n",
      " [ 9.95366132e+25 -6.40547874e+29 -8.56076143e+27]], State: [2.43690483e-02 9.95656404e+01 1.03428463e+00]\n",
      "Target: 5.037984191719347e+37, Q-value: -6.411269628120083e+31, Action: 2, State: [-2.24406523e-03  1.00079175e+02  8.40251991e-01], Reward: 0, Next state: [-9.19072411e-03  1.00047899e+02  8.46157848e-01], Next Q-values: [np.float64(-4.6423853879973426e+42), np.float64(5.597760213021497e+37), np.float64(-6.409271367185934e+31)]\n",
      "Error: 5.037990602988975e+37, Weights: [[-8.80834698e+36 -4.63960712e+40 -6.57119042e+38]\n",
      " [ 1.37060021e+32  5.59458891e+35  5.81065846e+33]\n",
      " [ 9.95366132e+25 -6.40547874e+29 -8.56076143e+27]], State: [-2.24406523e-03  1.00079175e+02  8.40251991e-01]\n",
      "Target: 4.533201935105255e+40, Q-value: 5.044752694181059e+40, Action: 2, State: [-9.19072411e-03  1.00047899e+02  8.46157848e-01], Reward: 0, Next state: [-5.02488079e-03  9.98915908e+01  8.91926423e-01], Next Q-values: [np.float64(-4.6351634157095636e+42), np.float64(5.58904206584318e+37), np.float64(5.036891039005839e+40)]\n",
      "Error: -5.115507590758037e+39, Weights: [[-8.80834698e+36 -4.63960712e+40 -6.57119042e+38]\n",
      " [ 1.37060021e+32  5.59458891e+35  5.81065846e+33]\n",
      " [-1.13055794e+34  5.04197943e+38  4.23318163e+36]], State: [-9.19072411e-03  1.00047899e+02  8.46157848e-01]\n",
      "Target: 5.054555360132516e+37, Q-value: -4.6351634157095636e+42, Action: 0, State: [-5.02488079e-03  9.98915908e+01  8.91926423e-01], Reward: 3.343628911294161, Next state: [1.69911568e-02 1.00378721e+02 6.80788079e-01], Next Q-values: [np.float64(-4.6576258005817625e+42), np.float64(5.616172622369462e+37), np.float64(-5.0870216327780445e+42)]\n",
      "Error: 4.635213961263165e+42, Weights: [[-8.80834698e+36 -4.63960712e+40 -6.57119042e+38]\n",
      " [ 1.37060021e+32  5.59458891e+35  5.81065846e+33]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [-5.02488079e-03  9.98915908e+01  8.91926423e-01]\n",
      "Target: 4.164329724520509e+45, Q-value: 4.6433482619567625e+45, Action: 0, State: [1.69911568e-02 1.00378721e+02 6.80788079e-01], Reward: 0, Next state: [-1.78138498e-02  1.00025525e+02  7.33916012e-01], Next Q-values: [np.float64(4.62703302724501e+45), np.float64(5.596443163530497e+37), np.float64(-5.0691462364506235e+42)]\n",
      "Error: -4.790185374362534e+44, Weights: [[-2.33794811e+39  4.62554936e+43  4.12769862e+41]\n",
      " [ 1.37060021e+32  5.59458891e+35  5.81065846e+33]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [1.69911568e-02 1.00378721e+02 6.80788079e-01]\n",
      "Target: 5.037834296057175e+37, Q-value: 5.596443163530497e+37, Action: 1, State: [-1.78138498e-02  1.00025525e+02  7.33916012e-01], Reward: -1, Next state: [1.65408998e-02 1.00045864e+02 7.54879032e-01], Next Q-values: [np.float64(-4.7644985841878015e+47), np.float64(5.59759366228575e+37), np.float64(-5.07018571403578e+42)]\n",
      "Error: -5.586088674733215e+36, Weights: [[-8.16245854e+41 -4.76207133e+45 -3.21982411e+43]\n",
      " [ 1.37060021e+32  5.59458891e+35  5.81065846e+33]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [-1.78138498e-02  1.00025525e+02  7.33916012e-01]\n",
      "Target: -4.97500660599825e+39, Q-value: -4.7644985841878015e+47, Action: 0, State: [1.65408998e-02 1.00045864e+02 7.54879032e-01], Reward: 0, Next state: [-1.61535156e-02  9.99255704e+01  8.24979164e-01], Next Q-values: [np.float64(-4.758792432066451e+47), np.float64(-5.527785117775833e+39), np.float64(-5.064120001145092e+42)]\n",
      "Error: 4.764498534437735e+47, Weights: [[-8.16245854e+41 -4.76207133e+45 -3.21982411e+43]\n",
      " [ 1.00880345e+34 -5.53156866e+37 -4.04161334e+35]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [1.65408998e-02 1.00045864e+02 7.54879032e-01]\n",
      "Target: 4.2879656266320044e+50, Q-value: 4.758673680209092e+50, Action: 0, State: [-1.61535156e-02  9.99255704e+01  8.24979164e-01], Reward: 0, Next state: [7.09304339e-03 1.00046361e+02 7.70550024e-01], Next Q-values: [np.float64(4.764406251813338e+50), np.float64(-5.534444492456391e+39), np.float64(-5.070217665382862e+42)]\n",
      "Error: -4.707080535770874e+49, Weights: [[ 7.87274684e+44  4.76192164e+48  3.59340022e+46]\n",
      " [ 1.00880345e+34 -5.53156866e+37 -4.04161334e+35]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [-1.61535156e-02  9.99255704e+01  8.24979164e-01]\n",
      "Target: -4.9829477455385584e+39, Q-value: -4.6584127969957834e+52, Action: 0, State: [7.09304339e-03 1.00046361e+02 7.70550024e-01], Reward: 0, Next state: [1.27836486e-02 1.00085114e+02 8.21345591e-01], Next Q-values: [np.float64(-4.6602366131076263e+52), np.float64(-5.536608606153953e+39), np.float64(-5.072203227004642e+42)]\n",
      "Error: 4.658412796995285e+52, Weights: [[ 7.68231736e+46 -4.65595786e+50 -3.84730936e+48]\n",
      " [ 1.00880345e+34 -5.53156866e+37 -4.04161334e+35]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [7.09304339e-03 1.00046361e+02 7.70550024e-01]\n",
      "Target: 4.2050148402553993e+55, Q-value: -5.536608606153953e+39, Action: 1, State: [1.27836486e-02 1.00085114e+02 8.21345591e-01], Reward: -1, Next state: [-6.84638171e-03  1.00345171e+02  7.00992155e-01], Next Q-values: [np.float64(4.672238711394888e+55), np.float64(-5.550945396552849e+39), np.float64(-5.0853302235472964e+42)]\n",
      "Error: 4.2050148402554e+55, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [ 1.00880345e+34 -5.53156866e+37 -4.04161334e+35]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [1.27836486e-02 1.00085114e+02 8.21345591e-01]\n",
      "Target: 3.782630133910041e+58, Q-value: 4.2233627886434095e+58, Action: 1, State: [-6.84638171e-03  1.00345171e+02  7.00992155e-01], Reward: -1, Next state: [-2.08808343e-02  9.98572551e+01  9.73292913e-01], Next Q-values: [np.float64(4.649619357799258e+55), np.float64(4.202922371011157e+58), np.float64(-5.06072169095912e+42)]\n",
      "Error: -4.4073265473336825e+57, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [ 5.37554322e+52  4.20859388e+56  3.45377040e+54]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [-6.84638171e-03  1.00345171e+02  7.00992155e-01]\n",
      "Target: 4.191265047761565e+55, Q-value: -5.06072169095912e+42, Action: 2, State: [-2.08808343e-02  9.98572551e+01  9.73292913e-01], Reward: 0, Next state: [1.62668994e-02 1.00015347e+02 9.20464179e-01], Next Q-values: [np.float64(4.6569611641795163e+55), np.float64(-4.3814068261619976e+60), np.float64(-5.068710239682857e+42)]\n",
      "Error: 4.1912650477620713e+55, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [ 3.07117942e+54 -4.38045341e+58 -3.05496363e+56]\n",
      " [ 4.69021631e+36 -5.06753807e+40 -4.28619508e+38]], State: [-2.08808343e-02  9.98572551e+01  9.73292913e-01]\n",
      "Target: 3.7769338093344053e+58, Q-value: -4.3814068261619976e+60, Action: 1, State: [1.62668994e-02 1.00015347e+02 9.20464179e-01], Reward: -1, Next state: [1.13790903e-02 1.00260294e+02 1.02209911e+00], Next Q-values: [np.float64(4.6684021251644543e+55), np.float64(-4.3921676853015875e+60), np.float64(4.1965931214826724e+58)]\n",
      "Error: 4.419176164255342e+60, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [ 3.07117942e+54 -4.38045341e+58 -3.05496363e+56]\n",
      " [-8.75171111e+52  4.18528223e+56  4.07932857e+54]], State: [1.62668994e-02 1.00015347e+02 9.20464179e-01]\n",
      "Target: 3.9832726013483014e+63, Q-value: 4.1965931214826724e+58, Action: 2, State: [1.13790903e-02 1.00260294e+02 1.02209911e+00], Reward: 0, Next state: [-1.17151456e-03  1.00226051e+02  9.92277467e-01], Next Q-values: [np.float64(4.6667970450887223e+55), np.float64(4.425858445942557e+63), np.float64(4.195147882019503e+58)]\n",
      "Error: 3.983230635417087e+63, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [ 7.19170057e+57  4.41547392e+61  4.06463840e+59]\n",
      " [-8.75171111e+52  4.18528223e+56  4.07932857e+54]], State: [1.13790903e-02 1.00260294e+02 1.02209911e+00]\n",
      "Target: 3.605068081799126e+66, Q-value: 4.425858445942557e+63, Action: 1, State: [-1.17151456e-03  1.00226051e+02  9.92277467e-01], Reward: -1, Next state: [-1.95393873e-03  1.00290903e+02  1.01914619e+00], Next Q-values: [np.float64(4.669826146394942e+55), np.float64(4.428732898490505e+63), np.float64(4.005631201999028e+66)]\n",
      "Error: 3.6006422233531834e+66, Weights: [[3.31191473e+49 4.65591652e+53 3.58569278e+51]\n",
      " [7.19170057e+57 4.41547392e+61 4.06463840e+59]\n",
      " [4.53255402e+60 3.99359879e+64 4.07125653e+62]], State: [-1.17151456e-03  1.00226051e+02  9.92277467e-01]\n",
      "Target: 3.259694555009344e+69, Q-value: 3.61964810676148e+69, Action: 1, State: [-1.95393873e-03  1.00290903e+02  1.01914619e+00], Reward: -1, Next state: [-2.09025137e-02  1.00353964e+02  9.04364597e-01], Next Q-values: [np.float64(4.6727209905022035e+55), np.float64(3.621882838899271e+69), np.float64(4.008102785915882e+66)]\n",
      "Error: -3.599535517521358e+68, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [-4.21813286e+62  3.60878592e+67  3.57284021e+65]\n",
      " [ 4.53255402e+60  3.99359879e+64  4.07125653e+62]], State: [-1.95393873e-03  1.00290903e+02  1.01914619e+00]\n",
      "Target: 3.61798193908016e+66, Q-value: 4.6727209905022035e+55, Action: 0, State: [-2.09025137e-02  1.00353964e+02  9.04364597e-01], Reward: 148.29236886371717, Next state: [2.80413914e-02 1.00650549e+02 9.84241784e-01], Next Q-values: [np.float64(4.6865585318986505e+55), np.float64(-3.59752642407695e+71), np.float64(4.019979932311289e+66)]\n",
      "Error: 3.617981939033433e+66, Weights: [[ 3.31191473e+49  4.65591652e+53  3.58569278e+51]\n",
      " [ 6.99109054e+64 -3.57391881e+69 -3.63272449e+67]\n",
      " [ 4.53255402e+60  3.99359879e+64  4.07125653e+62]], State: [-2.09025137e-02  1.00353964e+02  9.04364597e-01]\n",
      "Target: 3.2797371444989713e+69, Q-value: 3.654730163452787e+69, Action: 0, State: [2.80413914e-02 1.00650549e+02 9.84241784e-01], Reward: 0, Next state: [-1.77602433e-02  1.00358991e+02  1.00779579e+00], Next Q-values: [np.float64(3.644152382776635e+69), np.float64(-3.5871149859486196e+71), np.float64(4.008345679231256e+66)]\n",
      "Error: -3.7499301895381586e+68, Weights: [[-7.56249172e+63  3.63078829e+67  3.27197478e+65]\n",
      " [ 6.99109054e+64 -3.57391881e+69 -3.63272449e+67]\n",
      " [ 4.53255402e+60  3.99359879e+64  4.07125653e+62]], State: [2.80413914e-02 1.00650549e+02 9.84241784e-01]\n",
      "Target: 3.604851911067658e+66, Q-value: -3.5871149859486196e+71, Action: 1, State: [-1.77602433e-02  1.00358991e+02  1.00779579e+00], Reward: -1, Next state: [9.74317825e-03 1.00285404e+02 9.68435035e-01], Next Q-values: [np.float64(-3.7490402566560023e+71), np.float64(-3.5844707308399495e+71), np.float64(4.0053910122973976e+66)]\n",
      "Error: 3.5871510344677305e+71, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [ 6.99109054e+64 -3.57391881e+69 -3.63272449e+67]\n",
      " [ 4.53255402e+60  3.99359879e+64  4.07125653e+62]], State: [-1.77602433e-02  1.00358991e+02  1.00779579e+00]\n",
      "Target: 3.2470955441734096e+74, Q-value: 4.0053910122973976e+66, Action: 2, State: [9.74317825e-03 1.00285404e+02 9.68435035e-01], Reward: 0, Next state: [2.81271341e-03 1.00307930e+02 9.82221272e-01], Next Q-values: [np.float64(-3.7498872349987904e+71), np.float64(3.607883937970455e+74), np.float64(4.006296173270019e+66)]\n",
      "Error: 3.2470955041194996e+74, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [-6.37016841e+68  3.59645467e+72  3.61148297e+70]\n",
      " [ 4.53255402e+60  3.99359879e+64  4.07125653e+62]], State: [9.74317825e-03 1.00285404e+02 9.68435035e-01]\n",
      "Target: 2.9486386333869265e+77, Q-value: 3.2666990436688686e+77, Action: 2, State: [2.81271341e-03 1.00307930e+02 9.82221272e-01], Reward: 0, Next state: [-7.26967633e-03  1.00605231e+02  6.16270039e-01], Next Q-values: [np.float64(-3.760866438388997e+71), np.float64(3.6184441508907005e+74), np.float64(3.276265148207696e+77)]\n",
      "Error: -3.180604102819421e+76, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [-6.37016841e+68  3.59645467e+72  3.61148297e+70]\n",
      " [ 3.16370303e+71  3.25636285e+75  3.14460105e+73]], State: [2.81271341e-03 1.00307930e+02 9.82221272e-01]\n",
      "Target: 3.2574542382212535e+74, Q-value: 3.6184441508907005e+74, Action: 1, State: [-7.26967633e-03  1.00605231e+02  6.16270039e-01], Reward: -1, Next state: [1.40903704e-02 1.00631246e+02 6.54941779e-01], Next Q-values: [np.float64(-3.761853255681358e+71), np.float64(3.619393598023615e+74), np.float64(-3.177970773736998e+79)]\n",
      "Error: -3.60989912669447e+73, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [-6.37016841e+68  3.59645467e+72  3.61148297e+70]\n",
      " [-8.62975750e+72 -3.15783450e+77 -3.09261100e+75]], State: [-7.26967633e-03  1.00605231e+02  6.16270039e-01]\n",
      "Target: -3.3821905341025594e+71, Q-value: -3.61862436243951e+76, Action: 1, State: [1.40903704e-02 1.00631246e+02 6.54941779e-01], Reward: -1, Next state: [-2.41809061e-02  1.00526295e+02  8.18193935e-01], Next Q-values: [np.float64(-3.757989482336177e+71), np.float64(-3.614886378210146e+76), np.float64(-3.1747070485895614e+79)]\n",
      "Error: 3.618590540534169e+76, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [ 2.56057814e+70 -3.59578282e+74 -2.18855785e+72]\n",
      " [-8.62975750e+72 -3.15783450e+77 -3.09261100e+75]], State: [1.40903704e-02 1.00631246e+02 6.54941779e-01]\n",
      "Target: 3.2863173950089415e+79, Q-value: -3.1747070485895614e+79, Action: 2, State: [-2.41809061e-02  1.00526295e+02  8.18193935e-01], Reward: 0, Next state: [7.15792323e-03 1.00369045e+02 8.50984642e-01], Next Q-values: [np.float64(-3.752123781993554e+71), np.float64(3.651463772232157e+79), np.float64(-3.1697515259299237e+79)]\n",
      "Error: 6.461024443598504e+79, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [ 5.10128868e+73  3.63783697e+77  2.36777757e+75]\n",
      " [-8.62975750e+72 -3.15783450e+77 -3.09261100e+75]], State: [-2.41809061e-02  1.00526295e+02  8.18193935e-01]\n",
      "Target: 5.8497543399283904e+82, Q-value: -3.752123781993554e+71, Action: 0, State: [7.15792323e-03 1.00369045e+02 8.50984642e-01], Reward: -127.38838433603092, Next state: [-2.04732384e-03  1.00114269e+02  8.29360619e-01], Next Q-values: [np.float64(-3.7425921741648584e+71), np.float64(3.642190241694189e+79), np.float64(6.499727044364878e+82)]\n",
      "Error: 5.849754339965912e+82, Weights: [[-1.05909509e+66 -3.73801743e+69 -3.65811823e+67]\n",
      " [ 5.10128868e+73  3.63783697e+77  2.36777757e+75]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [7.15792323e-03 1.00369045e+02 8.50984642e-01]\n",
      "Target: 5.2836826809992115e+85, Q-value: 3.642190241694189e+79, Action: 1, State: [-2.04732384e-03  1.00114269e+02  8.29360619e-01], Reward: -1, Next state: [-1.17676010e-03  9.99828075e+01  8.54523548e-01], Next Q-values: [np.float64(5.8707585344435684e+85), np.float64(3.637413863984644e+79), np.float64(6.491206041033113e+82)]\n",
      "Error: 5.2836790388089696e+85, Weights: [[ 4.18720925e+79  5.87134259e+83  4.97805110e+81]\n",
      " [ 5.10128868e+73  3.63783697e+77  2.36777757e+75]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [-2.04732384e-03  1.00114269e+02  8.29360619e-01]\n",
      "Target: 4.7528545314159324e+88, Q-value: 5.289181650589358e+88, Action: 1, State: [-1.17676010e-03  9.99828075e+01  8.54523548e-01], Reward: -1, Next state: [1.30900195e-02 9.98295753e+01 5.65599281e-01], Next Q-values: [np.float64(5.8616179811731636e+85), np.float64(5.280949479351036e+88), np.float64(6.481105537775111e+82)]\n",
      "Error: -5.363271191734253e+87, Weights: [[ 4.18720925e+79  5.87134259e+83  4.97805110e+81]\n",
      " [-1.08174020e+82  5.28971663e+86  4.38207532e+84]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [-1.17676010e-03  9.99828075e+01  8.54523548e-01]\n",
      "Target: 5.2818397592177584e+85, Q-value: 5.8616179811731636e+85, Action: 0, State: [1.30900195e-02 9.98295753e+01 5.65599281e-01], Reward: 0, Next state: [-1.07386229e-02  9.99512114e+01  4.67746881e-01], Next Q-values: [np.float64(5.868710843575287e+85), np.float64(-5.307073865703461e+90), np.float64(6.4889506718511e+82)]\n",
      "Error: -5.7977822195540515e+84, Weights: [[ 4.18720925e+79  5.87134259e+83  4.97805110e+81]\n",
      " [ 6.20310951e+83 -5.30945194e+88 -4.53922078e+86]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [1.30900195e-02 9.98295753e+01 5.65599281e-01]\n",
      "Target: 5.8353928573302427e+82, Q-value: -5.72654372820781e+87, Action: 0, State: [-1.07386229e-02  9.99512114e+01  4.67746881e-01], Reward: 0, Next state: [-2.99548875e-03  9.98710991e+01  5.05753794e-01], Next Q-values: [np.float64(-5.721966274234621e+87), np.float64(-5.302837586884894e+90), np.float64(6.483769841478047e+82)]\n",
      "Error: 5.726602082136383e+87, Weights: [[-7.54743613e+81 -5.72918794e+85 -3.22944094e+83]\n",
      " [ 6.20310951e+83 -5.30945194e+88 -4.53922078e+86]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [-1.07386229e-02  9.99512114e+01  4.67746881e-01]\n",
      "Target: 5.138337863622659e+90, Q-value: 5.710843638430758e+90, Action: 0, State: [-2.99548875e-03  9.98710991e+01  5.05753794e-01], Reward: 0, Next state: [5.79597748e-04 9.98434160e+01 5.19281123e-01], Next Q-values: [np.float64(5.709264292914065e+90), np.float64(-5.301373903156567e+90), np.float64(6.481979780245415e+82)]\n",
      "Error: -5.725057748080992e+89, Weights: [[-6.15712948e+84  5.71807897e+88  2.67537082e+86]\n",
      " [ 6.20310951e+83 -5.30945194e+88 -4.53922078e+86]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [-2.99548875e-03  9.98710991e+01  5.05753794e-01]\n",
      "Target: 5.830907207777639e+82, Q-value: -5.651782839193695e+92, Action: 0, State: [5.79597748e-04 9.98434160e+01 5.19281123e-01], Reward: 0, Next state: [-2.27372301e-03  9.97939276e+01  5.54640979e-01], Next Q-values: [np.float64(-5.648991700648014e+92), np.float64(-5.298762395119889e+90), np.float64(6.478785786419599e+82)]\n",
      "Error: 5.651782839776786e+92, Weights: [[ 1.65336331e+86 -5.66049731e+90 -2.86871597e+88]\n",
      " [ 6.20310951e+83 -5.30945194e+88 -4.53922078e+86]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [5.79597748e-04 9.98434160e+01 5.19281123e-01]\n",
      "Target: 5.0470318425774505e+95, Q-value: -5.298762395119889e+90, Action: 1, State: [-2.27372301e-03  9.97939276e+01  5.54640979e-01], Reward: -1, Next state: [-3.68342516e-04  9.94764780e+01  1.80648334e-01], Next Q-values: [np.float64(5.607813158419389e+95), np.float64(-5.281737795905572e+90), np.float64(6.457979747765942e+82)]\n",
      "Error: 5.047084830201402e+95, Weights: [[ 3.29229424e+88  5.63727255e+93  2.93199543e+91]\n",
      " [ 6.20310951e+83 -5.30945194e+88 -4.53922078e+86]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [-2.27372301e-03  9.97939276e+01  5.54640979e-01]\n",
      "Target: 4.5040266788769986e+98, Q-value: 6.457979747765942e+82, Action: 2, State: [-3.68342516e-04  9.94764780e+01  1.80648334e-01], Reward: 0, Next state: [-7.99587824e-04  9.93597763e+01  1.28605748e-01], Next Q-values: [np.float64(5.601219107695842e+95), np.float64(5.004474087641109e+98), np.float64(6.450376136886605e+82)]\n",
      "Error: 4.504026678876998e+98, Weights: [[ 3.29229424e+88  5.63727255e+93  2.93199543e+91]\n",
      " [-1.14756729e+92  5.03668413e+96  2.79932003e+94]\n",
      " [-1.56242055e+77  6.49187067e+80  5.28327840e+78]], State: [-3.68342516e-04  9.94764780e+01  1.80648334e-01]\n",
      "Target: 4.0155251855787016e+101, Q-value: 5.601219107695842e+95, Action: 0, State: [-7.99587824e-04  9.93597763e+01  1.28605748e-01], Reward: 138.83712081207307, Next state: [1.39963367e-02 9.95805262e+01 5.14313266e-01], Next Q-values: [np.float64(5.613776471926948e+95), np.float64(5.015700514651665e+98), np.float64(4.4616946506430015e+101)]\n",
      "Error: 4.0155195843595936e+101, Weights: [[ 3.29229424e+88  5.63727255e+93  2.93199543e+91]\n",
      " [-1.14756729e+92  5.03668413e+96  2.79932003e+94]\n",
      " [-1.65902452e+94  4.48044711e+99  8.13644916e+96]], State: [-7.99587824e-04  9.93597763e+01  1.28605748e-01]\n",
      "Target: 3.570045434019042e+104, Q-value: 4.4616946506430015e+101, Action: 2, State: [1.39963367e-02 9.95805262e+01 5.14313266e-01], Reward: 0, Next state: [-1.83613758e-02  9.94203733e+01  6.17139071e-01], Next Q-values: [np.float64(3.9667171489100464e+104), np.float64(5.007662942700135e+98), np.float64(4.454527458519385e+101)]\n",
      "Error: 3.565583739368399e+104, Weights: [[-3.21076056e+097  3.98981128e+102  5.16418904e+099]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [-1.65902452e+094  4.48044711e+099  8.13644916e+096]], State: [1.39963367e-02 9.95805262e+01 5.14313266e-01]\n",
      "Target: 3.1811170627636935e+107, Q-value: 3.530164202791699e+107, Action: 2, State: [-1.83613758e-02  9.94203733e+01  6.17139071e-01], Reward: 0, Next state: [1.21006077e-02 9.95444398e+01 6.44486507e-01], Next Q-values: [np.float64(3.971668570679324e+104), np.float64(5.0139194009577816e+98), np.float64(3.534574514181881e+107)]\n",
      "Error: -3.490471400280055e+106, Weights: [[-3.21076056e+097  3.98981128e+102  5.16418904e+099]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 4.99051087e+101  3.55063153e+105  1.83382783e+103]], State: [-1.83613758e-02  9.94203733e+01  6.17139071e-01]\n",
      "Target: 3.5820298208107496e+104, Q-value: 3.971668570679324e+104, Action: 0, State: [1.21006077e-02 9.95444398e+01 6.44486507e-01], Reward: 158.5799438214039, Next state: [3.91291182e-03 9.97540272e+01 6.91379145e-01], Next Q-values: [np.float64(3.980033134234166e+104), np.float64(5.024488789346576e+98), np.float64(-3.426432507691246e+109)]\n",
      "Error: -3.8963874986857435e+103, Weights: [[-3.21076056e+097  3.98981128e+102  5.16418904e+099]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 6.45889082e+103 -3.43473338e+107 -2.13576800e+105]], State: [1.21006077e-02 9.95444398e+01 6.44486507e-01]\n",
      "Target: 4.513334077000575e+98, Q-value: -3.8294700192904e+106, Action: 0, State: [3.91291182e-03 9.97540272e+01 6.91379145e-01], Reward: 0, Next state: [-2.08716316e-02  9.95607108e+01  9.18423233e-01], Next Q-values: [np.float64(-3.822105889860341e+106), np.float64(5.0148156411117496e+98), np.float64(-3.419841258146158e+109)]\n",
      "Error: 3.8294700644237404e+106, Weights: [[-4.71807642e+100 -3.83873900e+104 -2.50600498e+102]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 6.45889082e+103 -3.43473338e+107 -2.13576800e+105]], State: [3.91291182e-03 9.97540272e+01 6.91379145e-01]\n",
      "Target: 3.4162606935202232e+109, Q-value: 3.799690565256951e+109, Action: 0, State: [-2.08716316e-02  9.95607108e+01  9.18423233e-01], Reward: 0, Next state: [1.88784267e-02 9.94606011e+01 8.23873061e-01], Next Q-values: [np.float64(3.79584521502247e+109), np.float64(5.0097469161314934e+98), np.float64(-3.416382304779139e+109)]\n",
      "Error: -3.834298717367276e+108, Weights: [[ 1.49371979e+103  3.81621187e+107  2.64510973e+105]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 6.45889082e+103 -3.43473338e+107 -2.13576800e+105]], State: [-2.08716316e-02  9.95607108e+01  9.18423233e-01]\n",
      "Target: 4.537071271271008e+98, Q-value: -3.7591952707161256e+111, Action: 0, State: [1.88784267e-02 9.94606011e+01 8.23873061e-01], Reward: 0, Next state: [1.76453916e-02 1.00083064e+02 1.15220761e+00], Next Q-values: [np.float64(-3.7828347186676727e+111), np.float64(5.041190301412231e+98), np.float64(-3.4378323664118807e+109)]\n",
      "Error: 3.7591952707165795e+111, Weights: [[ 8.01774421e+105 -3.77929294e+109 -3.49505793e+107]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 6.45889082e+103 -3.43473338e+107 -2.13576800e+105]], State: [1.88784267e-02 9.94606011e+01 8.23873061e-01]\n",
      "Target: 3.367289831147819e+114, Q-value: 3.738598033368994e+114, Action: 0, State: [1.76453916e-02 1.00083064e+02 1.15220761e+00], Reward: 0, Next state: [-1.51006436e-02  1.00158973e+02  1.15223239e+00], Next Q-values: [np.float64(3.741433145719799e+114), np.float64(5.045013683929961e+98), np.float64(-3.4404398832344276e+109)]\n",
      "Error: -3.713082022211747e+113, Weights: [[ 7.10478698e+108  3.73513892e+112  3.09360466e+110]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 6.45889082e+103 -3.43473338e+107 -2.13576800e+105]], State: [1.76453916e-02 1.00083064e+02 1.15220761e+00]\n",
      "Target: 4.525915340803261e+98, Q-value: -3.4404398832344276e+109, Action: 2, State: [-1.51006436e-02  1.00158973e+02  1.15223239e+00], Reward: 0, Next state: [-1.59718171e-02  9.98362482e+01  1.28007996e+00], Next Q-values: [np.float64(-3.673334314073785e+116), np.float64(5.028794823114734e+98), np.float64(-3.4293824429306886e+109)]\n",
      "Error: 3.4404398832796867e+109, Weights: [[-6.48083076e+110 -3.67881485e+114 -4.24730531e+112]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [ 6.45889082e+103 -3.43473338e+107 -2.13576800e+105]], State: [-1.51006436e-02  1.00158973e+02  1.15223239e+00]\n",
      "Target: 3.0958506545503357e+112, Q-value: -3.673334314073785e+116, Action: 0, State: [-1.59718171e-02  9.98362482e+01  1.28007996e+00], Reward: -11.370803754270753, Next state: [-1.15195187e-03  9.99095608e+01  1.19348370e+00], Next Q-values: [np.float64(-3.6759946653874094e+116), np.float64(5.032463089851e+98), np.float64(3.4398340606114843e+112)]\n",
      "Error: 3.673643899139241e+116, Weights: [[-6.48083076e+110 -3.67881485e+114 -4.24730531e+112]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [-5.18882675e+106  3.44247454e+110  3.96205050e+108]], State: [-1.59718171e-02  9.98362482e+01  1.28007996e+00]\n",
      "Target: 3.301127895830275e+119, Q-value: 3.6611965239206856e+119, Action: 0, State: [-1.15195187e-03  9.99095608e+01  1.19348370e+00], Reward: 0, Next state: [2.43445084e-02 1.00092043e+02 1.27316821e+00], Next Q-values: [np.float64(3.6679198842558614e+119), np.float64(5.04167644128165e+98), np.float64(3.446147418322246e+112)]\n",
      "Error: -3.6006862809041043e+118, Weights: [[-5.87395767e+113  3.66394943e+117  4.69831063e+115]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [-5.18882675e+106  3.44247454e+110  3.96205050e+108]], State: [-1.15195187e-03  9.99095608e+01  1.19348370e+00]\n",
      "Target: 3.0846971808537352e+112, Q-value: -3.564608966937923e+121, Action: 0, State: [2.43445084e-02 1.00092043e+02 1.27316821e+00], Reward: 0, Next state: [-1.82621726e-02  9.95524452e+01  9.43054392e-01], Next Q-values: [np.float64(-3.545254706529157e+121), np.float64(5.0144062180720753e+98), np.float64(3.4274413120597056e+112)]\n",
      "Error: 3.56460897002262e+121, Weights: [[ 3.56042153e+114 -3.56079036e+119 -4.25037729e+117]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [-5.18882675e+106  3.44247454e+110  3.96205050e+108]], State: [2.43445084e-02 1.00092043e+02 1.27316821e+00]\n",
      "Target: 3.1924998117956793e+124, Q-value: 3.4274413120597056e+112, Action: 2, State: [-1.82621726e-02  9.95524452e+01  9.43054392e-01], Reward: 0, Next state: [9.48084292e-03 9.95084517e+01 9.11227485e-01], Next Q-values: [np.float64(3.5472220131063105e+124), np.float64(5.012181466981737e+98), np.float64(3.4259140956521784e+112)]\n",
      "Error: 3.192499811792252e+124, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [-5.18882675e+106  3.44247454e+110  3.96205050e+108]], State: [-1.82621726e-02  9.95524452e+01  9.43054392e-01]\n",
      "Target: 2.8557979179931372e+127, Q-value: 5.012181466981737e+98, Action: 1, State: [9.48084292e-03 9.95084517e+01 9.11227485e-01], Reward: -1, Next state: [2.32065376e-03 9.98313440e+01 8.55050310e-01], Next Q-values: [np.float64(3.558705424440996e+124), np.float64(5.0284288150766106e+98), np.float64(3.1731087977701526e+127)]\n",
      "Error: 2.8557979179931372e+127, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [-1.14756729e+092  5.03668413e+096  2.79932003e+094]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [9.48084292e-03 9.95084517e+01 9.11227485e-01]\n",
      "Target: 2.561924386066934e+130, Q-value: 2.8371900093643293e+130, Action: 1, State: [2.32065376e-03 9.98313440e+01 8.55050310e-01], Reward: -1, Next state: [-6.33475546e-04  1.00164267e+02  5.92835048e-01], Next Q-values: [np.float64(3.570452994520542e+124), np.float64(2.8465826511854824e+130), np.float64(3.1836108807188835e+127)]\n",
      "Error: -2.7526562329739528e+129, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [ 2.70753715e+124  2.84176029e+128  2.60228155e+126]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [2.32065376e-03 9.98313440e+01 8.55050310e-01]\n",
      "Target: 2.858543143772757e+127, Q-value: -2.7242015130759216e+132, Action: 1, State: [-6.33475546e-04  1.00164267e+02  5.92835048e-01], Reward: -1, Next state: [-4.27668152e-03  9.99313841e+01  4.25678075e-01], Next Q-values: [np.float64(3.5620764412878404e+124), np.float64(-2.7178291148282545e+132), np.float64(3.1761590486363966e+127)]\n",
      "Error: 2.7242300985073592e+132, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [-6.11720833e+125 -2.71959611e+130 -2.32763675e+128]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [-6.33475546e-04  1.00164267e+02  5.92835048e-01]\n",
      "Target: 2.4626152160955365e+135, Q-value: 2.7241837151624604e+135, Action: 1, State: [-4.27668152e-03  9.99313841e+01  4.25678075e-01], Reward: -1, Next state: [1.53096323e-02 1.00373056e+02 5.21820732e-01], Next Q-values: [np.float64(3.577862844046068e+124), np.float64(2.7362391289950406e+135), np.float64(3.1902251481564913e+127)]\n",
      "Error: -2.6156849906692398e+134, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [-1.73185036e+128  2.72598553e+133  1.61269144e+131]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [-4.27668152e-03  9.99313841e+01  4.25678075e-01]\n",
      "Target: 2.876129215987447e+127, Q-value: -2.5963371807612756e+137, Action: 1, State: [1.53096323e-02 1.00373056e+02 5.21820732e-01], Reward: -1, Next state: [-4.02646819e-03  1.00545096e+02  5.41948316e-01], Next Q-values: [np.float64(3.5840038886464584e+124), np.float64(-2.600789460345776e+137), np.float64(3.195699128874941e+127)]\n",
      "Error: 2.5963371810488886e+137, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [ 1.11691332e+131 -2.58663036e+135 -1.09731284e+133]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [1.53096323e-02 1.00373056e+02 5.21820732e-01]\n",
      "Target: 2.3548957766032504e+140, Q-value: 3.5840038886464584e+124, Action: 0, State: [-4.02646819e-03  1.00545096e+02  5.41948316e-01], Reward: 1.0761363701206506, Next state: [-8.41435215e-03  1.00500793e+02  5.66741319e-01], Next Q-values: [np.float64(3.582435982489348e+124), np.float64(2.6165508628925005e+140), np.float64(3.19429857159082e+127)]\n",
      "Error: 2.35489577660325e+140, Weights: [[ 8.67822136e+118  3.56432917e+122  4.53409644e+120]\n",
      " [ 3.97601368e+134  2.60343634e+138  1.35372526e+136]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [-4.02646819e-03  1.00545096e+02  5.41948316e-01]\n",
      "Target: 2.14108692382273e+143, Q-value: 3.19429857159082e+127, Action: 2, State: [-8.41435215e-03  1.00500793e+02  5.66741319e-01], Reward: 0, Next state: [1.46827192e-04 1.00472140e+02 5.81620900e-01], Next Q-values: [np.float64(2.3789854709141443e+143), np.float64(2.615806945998567e+140), np.float64(3.193392345317777e+127)]\n",
      "Error: 2.1410869238227297e+143, Weights: [[-9.48191294e+136  2.36773223e+141  1.27623180e+139]\n",
      " [ 3.97601368e+134  2.60343634e+138  1.35372526e+136]\n",
      " [-5.83019824e+121  3.17821162e+125  3.01070097e+123]], State: [-8.41435215e-03  1.00500793e+02  5.66741319e-01]\n",
      "Target: 1.9490195509006992e+146, Q-value: 2.3789854709141443e+143, Action: 0, State: [1.46827192e-04 1.00472140e+02 5.81620900e-01], Reward: 53.92531558011484, Next state: [5.38624790e-03 1.00637094e+02 4.85441386e-01], Next Q-values: [np.float64(2.3828788480642317e+143), np.float64(2.6200884057724733e+140), np.float64(2.1655772787785547e+146)]\n",
      "Error: 1.9466405654297851e+146, Weights: [[-9.48191294e+136  2.36773223e+141  1.27623180e+139]\n",
      " [ 3.97601368e+134  2.60343634e+138  1.35372526e+136]\n",
      " [-1.80158594e+140  2.15180934e+144  1.21344243e+142]], State: [1.46827192e-04 1.00472140e+02 5.81620900e-01]\n",
      "Target: 1.7666092660907946e+149, Q-value: 2.6200884057724733e+140, Action: 1, State: [5.38624790e-03 1.00637094e+02 4.85441386e-01], Reward: -1, Next state: [-6.82102297e-03  1.00359056e+02  3.78347224e-01], Next Q-values: [np.float64(1.9628991845453272e+149), np.float64(2.6128353327790903e+140), np.float64(2.159581470650469e+146)]\n",
      "Error: 1.7666092634707061e+149, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [ 3.97601368e+134  2.60343634e+138  1.35372526e+136]\n",
      " [-1.80158594e+140  2.15180934e+144  1.21344243e+142]], State: [5.38624790e-03 1.00637094e+02 4.85441386e-01]\n",
      "Target: 1.602744464513839e+152, Q-value: 1.784280190903509e+152, Action: 1, State: [-6.82102297e-03  1.00359056e+02  3.78347224e-01], Reward: -1, Next state: [1.39942572e-04 1.00165441e+02 2.52426020e-01], Next Q-values: [np.float64(1.959098135700359e+149), np.float64(1.7808271827931544e+152), np.float64(2.1553999476629886e+146)]\n",
      "Error: -1.8153572638966995e+151, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [ 9.51539543e+145  1.77786422e+150  8.57585249e+147]\n",
      " [-1.80158594e+140  2.15180934e+144  1.21344243e+142]], State: [-6.82102297e-03  1.00359056e+02  3.78347224e-01]\n",
      "Target: 1.7624492169024833e+149, Q-value: 2.1553999476629886e+146, Action: 2, State: [1.39942572e-04 1.00165441e+02 2.52426020e-01], Reward: 0, Next state: [-9.20047980e-04  1.00123316e+02  2.75979953e-01], Next Q-values: [np.float64(1.9582769076694258e+149), np.float64(-1.806340234957924e+154), np.float64(2.1544963582349516e+146)]\n",
      "Error: 1.7602938169548203e+149, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [ 1.24777475e+148 -1.80409678e+152 -6.78259529e+149]\n",
      " [-1.80158594e+140  2.15180934e+144  1.21344243e+142]], State: [1.39942572e-04 1.00165441e+02 2.52426020e-01]\n",
      "Target: 1.5855748802991146e+152, Q-value: 1.7653947974552135e+152, Action: 2, State: [-9.20047980e-04  1.00123316e+02  2.75979953e-01], Reward: 0, Next state: [-8.11999931e-03  9.99160280e+01  5.00796576e-01], Next Q-values: [np.float64(1.954248151664663e+149), np.float64(-1.8026158153513993e+154), np.float64(1.7617498669990162e+152)]\n",
      "Error: -1.798199171560989e+151, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [ 1.24777475e+148 -1.80409678e+152 -6.78259529e+149]\n",
      " [ 2.46322029e+144  1.76320822e+150  4.44345175e+147]], State: [-9.20047980e-04  1.00123316e+02  2.75979953e-01]\n",
      "Target: 1.7545082461966062e+149, Q-value: -1.8026158153513993e+154, Action: 1, State: [-8.11999931e-03  9.99160280e+01  5.00796576e-01], Reward: -1, Next state: [3.57416009e-03 9.96717150e+01 3.57805598e-01], Next Q-values: [np.float64(1.949453606885118e+149), np.float64(-1.7981984599376095e+154), np.float64(-1.776949539616246e+154)]\n",
      "Error: 1.802633360433861e+154, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [ 1.24777475e+148 -1.80409678e+152 -6.78259529e+149]\n",
      " [ 1.65689274e+147 -1.78278456e+152 -4.91823470e+149]], State: [-8.11999931e-03  9.99160280e+01  5.00796576e-01]\n",
      "Target: 1.60782489692514e+157, Q-value: 1.793440944015834e+157, Action: 1, State: [3.57416009e-03 9.96717150e+01 3.57805598e-01], Reward: -1, Next state: [-1.41835584e-02  9.92826507e+01  7.08463080e-01], Next Q-values: [np.float64(1.941883857291126e+149), np.float64(1.7864721076946e+157), np.float64(-1.7700306107249235e+154)]\n",
      "Error: -1.8561604709069408e+156, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [-1.46249039e+151  1.79931556e+155  9.02074355e+152]\n",
      " [ 1.65689274e+147 -1.78278456e+152 -4.91823470e+149]], State: [3.57416009e-03 9.96717150e+01 3.57805598e-01]\n",
      "Target: 1.7455626526869037e+149, Q-value: -1.7700306107249235e+154, Action: 2, State: [-1.41835584e-02  9.92826507e+01  7.08463080e-01], Reward: 0, Next state: [1.38322094e-02 9.91619662e+01 6.25345617e-01], Next Q-values: [np.float64(1.9395140585410041e+149), np.float64(-1.816761397850226e+159), np.float64(-1.7678749729263722e+154)]\n",
      "Error: 1.7700480663514505e+154, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 1.65689274e+147 -1.78278456e+152 -4.91823470e+149]], State: [-1.41835584e-02  9.92826507e+01  7.08463080e-01]\n",
      "Target: 1.5640260502619475e+157, Q-value: 1.9395140585410041e+149, Action: 0, State: [1.38322094e-02 9.91619662e+01 6.25345617e-01], Reward: -88.6488157618274, Next state: [-3.77395151e-03  9.89846685e+01  5.08097392e-01], Next Q-values: [np.float64(1.936033136086055e+149), np.float64(-1.8135054812127644e+159), np.float64(1.7378067225132748e+157)]\n",
      "Error: 1.564026030866807e+157, Weights: [[ 2.85810285e+141  1.95583380e+147  1.13220811e+145]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-2.51039232e+151  1.75556785e+155  1.25352188e+153]], State: [1.38322094e-02 9.91619662e+01 6.25345617e-01]\n",
      "Target: 1.3821834082203853e+160, Q-value: 1.7378067225132748e+157, Action: 2, State: [-3.77395151e-03  9.89846685e+01  5.08097392e-01], Reward: 0, Next state: [2.50848609e-03 9.90192649e+01 5.19193716e-01], Next Q-values: [np.float64(1.5357593424670948e+160), np.float64(-1.8141400430271927e+159), np.float64(1.7384154600298483e+157)]\n",
      "Error: 1.380445601497872e+160, Weights: [[ 2.16339355e+154  1.55091896e+158  9.78056824e+155]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-2.51039232e+151  1.75556785e+155  1.25352188e+153]], State: [-3.77395151e-03  9.89846685e+01  5.08097392e-01]\n",
      "Target: 1.219485896192421e+163, Q-value: 1.3530666026031034e+163, Action: 2, State: [2.50848609e-03 9.90192649e+01 5.19193716e-01], Reward: 0, Next state: [8.85344794e-03 9.91587821e+01 6.80621249e-01], Next Q-values: [np.float64(1.5379389441316446e+160), np.float64(-1.816706681747806e+159), np.float64(1.35498432910269e+163)]\n",
      "Error: -1.3358070641068242e+162, Weights: [[ 2.16339355e+154  1.55091896e+158  9.78056824e+155]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-5.20975987e+156  1.36643126e+161  7.01402063e+158]], State: [2.50848609e-03 9.90192649e+01 5.19193716e-01]\n",
      "Target: 1.3919637552573346e+160, Q-value: -1.2980768569220517e+165, Action: 2, State: [8.85344794e-03 9.91587821e+01 6.80621249e-01], Reward: 0, Next state: [6.92286637e-03 9.97190060e+01 6.68732269e-01], Next Q-values: [np.float64(1.5466263947303718e+160), np.float64(-1.8269696156400583e+159), np.float64(-1.3054096053797954e+165)]\n",
      "Error: 1.2980907765596044e+165, Weights: [[ 2.16339355e+154  1.55091896e+158  9.78056824e+155]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-3.40295104e+158 -1.30904202e+163 -6.86528613e+160]], State: [8.85344794e-03 9.91587821e+01 6.80621249e-01]\n",
      "Target: 1.1604016347694823e+168, Q-value: 1.2823078126881603e+168, Action: 2, State: [6.92286637e-03 9.97190060e+01 6.68732269e-01], Reward: 0, Next state: [1.26132541e-02 1.00262399e+02 1.12239730e+00], Next Q-values: [np.float64(1.555098358428174e+160), np.float64(-1.8369546954935007e+159), np.float64(1.2893351497438692e+168)]\n",
      "Error: -1.2190617791867803e+167, Weights: [[ 2.16339355e+154  1.55091896e+158  9.78056824e+155]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 1.14891762e+162  1.28586196e+166  8.82821637e+163]], State: [6.92286637e-03 9.97190060e+01 6.68732269e-01]\n",
      "Target: 1.406163595808929e+160, Q-value: 1.555098358428174e+160, Action: 0, State: [1.26132541e-02 1.00262399e+02 1.12239730e+00], Reward: 211.1358939598631, Next state: [-7.17267045e-03  1.00734341e+02  9.81689011e-01], Next Q-values: [np.float64(1.5624039953432542e+160), np.float64(-1.845591794270004e+159), np.float64(-1.2116893142927915e+170)]\n",
      "Error: -1.4893476261924516e+159, Weights: [[ 2.16339355e+154  1.55091896e+158  9.78056824e+155]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-8.32451004e+163 -1.20277767e+168 -8.06397733e+165]], State: [1.26132541e-02 1.00262399e+02 1.12239730e+00]\n",
      "Target: -1.65844788701029e+159, Q-value: -1.2116893142927915e+170, Action: 2, State: [-7.17267045e-03  1.00734341e+02  9.81689011e-01], Reward: 0, Next state: [-2.86067376e-02  1.00576671e+02  1.23701866e+00], Next Q-values: [np.float64(-1.4864737192418154e+162), np.float64(-1.842719874455878e+159), np.float64(-1.2098134654790495e+170)]\n",
      "Error: 1.2116893142762072e+170, Weights: [[-1.85691807e+156 -1.47774646e+160 -1.66185919e+158]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-8.32451004e+163 -1.20277767e+168 -8.06397733e+165]], State: [-7.17267045e-03  1.00734341e+02  9.81689011e-01]\n",
      "Target: 1.0999847209279145e+173, Q-value: 1.226563369940051e+173, Action: 2, State: [-2.86067376e-02  1.00576671e+02  1.23701866e+00], Reward: 0, Next state: [-1.36769355e-03  1.00216320e+02  1.53952808e+00], Next Q-values: [np.float64(-1.4811989735401644e+162), np.float64(-1.8361378210040535e+159), np.float64(1.2222052454754605e+173)]\n",
      "Error: -1.2657864901213655e+172, Weights: [[-1.85691807e+156 -1.47774646e+160 -1.66185919e+158]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [-8.69937265e+166  1.21938447e+171  1.18869569e+169]], State: [-2.86067376e-02  1.00576671e+02  1.23701866e+00]\n",
      "Target: -1.6532224105040386e+159, Q-value: -1.4811989735401644e+162, Action: 0, State: [-1.36769355e-03  1.00216320e+02  1.53952808e+00], Reward: 257.1713018308131, Next state: [2.75234185e-02 1.00258606e+02 1.55845684e+00], Next Q-values: [np.float64(-1.4818270511807374e+162), np.float64(-1.8369137894489316e+159), np.float64(-1.2643948812533795e+175)]\n",
      "Error: 1.4795457511296604e+162, Weights: [[-1.85691807e+156 -1.47774646e+160 -1.66185919e+158]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 3.61230283e+169 -1.26089207e+173 -1.55391455e+171]], State: [-1.36769355e-03  1.00216320e+02  1.53952808e+00]\n",
      "Target: 1.3276273543186446e+165, Q-value: 1.485453931418915e+165, Action: 0, State: [2.75234185e-02 1.00258606e+02 1.55845684e+00], Reward: 0, Next state: [-2.37937113e-02  9.95657384e+01  1.34227588e+00], Next Q-values: [np.float64(1.475141504798494e+165), np.float64(-1.8242057445472286e+159), np.float64(-1.2556251601975842e+175)]\n",
      "Error: -1.578265771002704e+164, Weights: [[-2.04213437e+158  1.48126856e+163  2.27614037e+161]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 3.61230283e+169 -1.26089207e+173 -1.55391455e+171]], State: [2.75234185e-02 1.00258606e+02 1.55845684e+00]\n",
      "Target: -1.6382412595856738e+159, Q-value: -1.561054370199747e+167, Action: 0, State: [-2.37937113e-02  9.95657384e+01  1.34227588e+00], Reward: 0, Next state: [1.68470329e-02 9.93516652e+01 1.10220427e+00], Next Q-values: [np.float64(-1.5576403731001422e+167), np.float64(-1.820268066206304e+159), np.float64(-1.2528884768814246e+175)]\n",
      "Error: 1.5610543538173344e+167, Weights: [[-4.34596907e+161 -1.56753458e+165 -2.43689768e+163]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 3.61230283e+169 -1.26089207e+173 -1.55391455e+171]], State: [-2.37937113e-02  9.95657384e+01  1.34227588e+00]\n",
      "Target: 1.3940900082154082e+170, Q-value: -1.2528884768814246e+175, Action: 2, State: [1.68470329e-02 9.93516652e+01 1.10220427e+00], Reward: 0, Next state: [1.42488449e-03 9.97461155e+01 1.06658850e+00], Next Q-values: [np.float64(1.54898889801712e+170), np.float64(-1.8274923423549452e+159), np.float64(-1.2578565901971546e+175)]\n",
      "Error: 1.2529024177815067e+175, Weights: [[-3.71867364e+164  1.55270776e+168  2.09292871e+166]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 3.61230283e+169 -1.26089207e+173 -1.55391455e+171]], State: [1.68470329e-02 9.93516652e+01 1.10220427e+00]\n",
      "Target: 1.1230835510654262e+178, Q-value: 1.54898889801712e+170, Action: 0, State: [1.42488449e-03 9.97461155e+01 1.06658850e+00], Reward: 86.079115772624, Next state: [8.57044984e-03 1.00339658e+02 9.30563740e-01], Next Q-values: [np.float64(1.5581763819012694e+170), np.float64(-1.838357571482609e+159), np.float64(1.2478706122949179e+178)]\n",
      "Error: 1.1230835355755371e+178, Weights: [[-3.71867364e+164  1.55270776e+168  2.09292871e+166]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 2.11438113e+172  1.24351852e+176  1.37940048e+174]], State: [1.42488449e-03 9.97461155e+01 1.06658850e+00]\n",
      "Target: 1.0101172618661418e+181, Q-value: -1.838357571482609e+159, Action: 1, State: [8.57044984e-03 1.00339658e+02 9.30563740e-01], Reward: -1, Next state: [-1.04583166e-02  1.00180043e+02  8.63355617e-01], Next Q-values: [np.float64(1.122352513184602e+181), np.float64(-1.835428887208432e+159), np.float64(1.2458764567115641e+178)]\n",
      "Error: 1.0101172618661418e+181, Weights: [[ 1.60026431e+174  1.12023220e+179  1.19786799e+177]\n",
      " [-6.78046372e+152 -1.83207382e+157 -6.55123863e+154]\n",
      " [ 2.11438113e+172  1.24351852e+176  1.37940048e+174]], State: [8.57044984e-03 1.00339658e+02 9.30563740e-01]\n",
      "Target: 9.162558083659807e+183, Q-value: 1.0154541688316728e+184, Action: 1, State: [-1.04583166e-02  1.00180043e+02  8.63355617e-01], Reward: -1, Next state: [-2.99971898e-03  1.00441097e+02  4.58269351e-01], Next Q-values: [np.float64(1.1252284048004898e+181), np.float64(1.018062009295534e+184), np.float64(1.2490668535292008e+178)]\n",
      "Error: -9.919836046569209e+182, Weights: [[1.60026431e+174 1.12023220e+179 1.19786799e+177]\n",
      " [8.65715933e+177 1.01354820e+182 9.39978497e+179]\n",
      " [2.11438113e+172 1.24351852e+176 1.37940048e+174]], State: [-1.04583166e-02  1.00180043e+02  8.63355617e-01]\n",
      "Target: 1.0145323010003996e+181, Q-value: -9.880117172282338e+185, Action: 1, State: [-2.99971898e-03  1.00441097e+02  4.58269351e-01], Reward: -1, Next state: [1.25895958e-02 1.00621454e+02 5.35850280e-01], Next Q-values: [np.float64(1.1272581122226663e+181), np.float64(-9.897923205083542e+185), np.float64(1.2513203546805062e+178)]\n",
      "Error: 9.880218625512438e+185, Weights: [[ 1.60026431e+174  1.12023220e+179  1.19786799e+177]\n",
      " [ 1.04610502e+180 -9.83634117e+183 -8.47034832e+181]\n",
      " [ 2.11438113e+172  1.24351852e+176  1.37940048e+174]], State: [-2.99971898e-03  1.00441097e+02  4.58269351e-01]\n",
      "Target: 8.966755556036345e+188, Q-value: 1.2513203546805062e+178, Action: 2, State: [1.25895958e-02 1.00621454e+02 5.35850280e-01], Reward: 0, Next state: [-1.38777841e-02  1.00492353e+02  6.33563118e-01], Next Q-values: [np.float64(1.1258235906752716e+181), np.float64(9.963061728929271e+188), np.float64(1.249728392321096e+178)]\n",
      "Error: 8.966755555911213e+188, Weights: [[ 1.60026431e+174  1.12023220e+179  1.19786799e+177]\n",
      " [-2.95332688e+182  9.91396363e+186  4.51933103e+184]\n",
      " [ 2.11438113e+172  1.24351852e+176  1.37940048e+174]], State: [1.25895958e-02 1.00621454e+02 5.35850280e-01]\n",
      "Target: 8.139262398102479e+191, Q-value: 9.067206510947344e+191, Action: 2, State: [-1.38777841e-02  1.00492353e+02  6.33563118e-01], Reward: 0, Next state: [2.03350326e-03 1.00231680e+02 5.03227771e-01], Next Q-values: [np.float64(1.1228878365116008e+181), np.float64(9.937159740511585e+188), np.float64(9.043624886780532e+191)]\n",
      "Error: -9.279441128448652e+190, Weights: [[ 1.60026431e+174  1.12023220e+179  1.19786799e+177]\n",
      " [-2.95332688e+182  9.91396363e+186  4.51933103e+184]\n",
      " [ 1.12887828e+186  9.02247977e+189  4.80483848e+187]], State: [-1.38777841e-02  1.00492353e+02  6.33563118e-01]\n",
      "Target: 8.949617854011184e+188, Q-value: -9.256592817797337e+193, Action: 2, State: [2.03350326e-03 1.00231680e+02 5.03227771e-01], Reward: 0, Next state: [5.89529257e-03 1.00300788e+02 5.22764389e-01], Next Q-values: [np.float64(1.1236643403597581e+181), np.float64(9.944019837790205e+188), np.float64(-9.262986158725298e+193)]\n",
      "Error: 9.256682313975878e+193, Weights: [[ 1.60026431e+174  1.12023220e+179  1.19786799e+177]\n",
      " [-2.95332688e+182  9.91396363e+186  4.51933103e+184]\n",
      " [ 1.29906958e+188 -9.23490397e+191 -5.83106327e+189]], State: [2.03350326e-03 1.00231680e+02 5.03227771e-01]\n",
      "Target: 8.37422438892285e+196, Q-value: 1.1236643403597581e+181, Action: 0, State: [5.89529257e-03 1.00300788e+02 5.22764389e-01], Reward: 56.11673396585388, Next state: [-2.29913459e-03  1.00383781e+02  4.90492998e-01], Next Q-values: [np.float64(1.124590194236925e+181), np.float64(9.952233231420348e+188), np.float64(9.304693765469833e+196)]\n",
      "Error: 8.374224388922848e+196, Weights: [[ 1.60026431e+174  1.12023220e+179  1.19786799e+177]\n",
      " [-2.95332688e+182  9.91396363e+186  4.51933103e+184]\n",
      " [ 1.89534006e+190  9.26889331e+194  4.65238855e+192]], State: [5.89529257e-03 1.00300788e+02 5.22764389e-01]\n",
      "Target: 7.563649285405343e+199, Q-value: 9.952233231420348e+188, Action: 1, State: [-2.29913459e-03  1.00383781e+02  4.90492998e-01], Reward: -1, Next state: [-8.06308558e-03  1.00053309e+02  3.74985021e-01], Next Q-values: [np.float64(8.404054761561493e+199), np.float64(9.919418141613241e+188), np.float64(9.274008889613263e+196)]\n",
      "Error: 7.563649285305821e+199, Weights: [[ 4.93685028e+193  8.39941301e+197  4.37774629e+195]\n",
      " [-2.95332688e+182  9.91396363e+186  4.51933103e+184]\n",
      " [ 1.89534006e+190  9.26889331e+194  4.65238855e+192]], State: [-2.29913459e-03  1.00383781e+02  4.90492998e-01]\n",
      "Target: 6.848256722886579e+202, Q-value: 8.404054761561493e+199, Action: 0, State: [-8.06308558e-03  1.00053309e+02  3.74985021e-01], Reward: 0, Next state: [1.06287180e-02 1.00215316e+02 4.01001715e-01], Next Q-values: [np.float64(8.4176738871144e+199), np.float64(7.609174136540643e+202), np.float64(9.289037292487193e+196)]\n",
      "Error: 6.839852668125017e+202, Weights: [[ 4.93685028e+193  8.39941301e+197  4.37774629e+195]\n",
      " [-1.73898477e+196  7.59267714e+200  3.70991701e+198]\n",
      " [ 1.89534006e+190  9.26889331e+194  4.65238855e+192]], State: [-8.06308558e-03  1.00053309e+02  3.74985021e-01]\n",
      "Target: 6.163638774819435e+205, Q-value: 7.609174136540643e+202, Action: 1, State: [1.06287180e-02 1.00215316e+02 4.01001715e-01], Reward: -1, Next state: [-1.32227965e-02  1.00070691e+02  5.55275523e-01], Next Q-values: [np.float64(6.84848752757715e+205), np.float64(7.598250485905614e+202), np.float64(9.27570386363431e+196)]\n",
      "Error: 6.1560296006828945e+205, Weights: [[-5.51502680e+199  6.84350731e+203  2.56484667e+201]\n",
      " [-1.73898477e+196  7.59267714e+200  3.70991701e+198]\n",
      " [ 1.89534006e+190  9.26889331e+194  4.65238855e+192]], State: [1.06287180e-02 1.00215316e+02 4.01001715e-01]\n",
      "Target: 5.549997783932379e+208, Q-value: 9.27570386363431e+196, Action: 2, State: [-1.32227965e-02  1.00070691e+02  5.55275523e-01], Reward: 0, Next state: [7.41722413e-03 9.99554297e+01 4.93088444e-01], Next Q-values: [np.float64(6.840583570327865e+205), np.float64(6.16666420436931e+208), np.float64(9.264991553928035e+196)]\n",
      "Error: 5.549997783923104e+208, Weights: [[-5.51502680e+199  6.84350731e+203  2.56484667e+201]\n",
      " [ 6.54306854e+202  6.16929210e+206  2.46858213e+204]\n",
      " [ 1.89534006e+190  9.26889331e+194  4.65238855e+192]], State: [-1.32227965e-02  1.00070691e+02  5.55275523e-01]\n",
      "Target: 4.984910096701677e+211, Q-value: 5.55159762088973e+211, Action: 2, State: [7.41722413e-03 9.99554297e+01 4.93088444e-01], Reward: 0, Next state: [-8.08824704e-03  9.97246425e+01  5.22288317e-01], Next Q-values: [np.float64(6.8247972086372005e+205), np.float64(6.152433376787365e+208), np.float64(5.538788996335197e+211)]\n",
      "Error: -5.666875241880528e+210, Weights: [[-5.51502680e+199  6.84350731e+203  2.56484667e+201]\n",
      " [ 6.54306854e+202  6.16929210e+206  2.46858213e+204]\n",
      " [-7.33864910e+205  5.55392112e+209  3.08177792e+207]], State: [7.41722413e-03 9.99554297e+01 4.93088444e-01]\n",
      "Target: 5.550412722407987e+208, Q-value: 6.8247972086372005e+205, Action: 0, State: [-8.08824704e-03  9.97246425e+01  5.22288317e-01], Reward: 72.42060082223674, Next state: [1.54547498e-02 9.99623046e+01 6.42395690e-01], Next Q-values: [np.float64(6.841092305057642e+205), np.float64(6.167125247119985e+208), np.float64(-5.606873613676237e+213)]\n",
      "Error: 5.5435879251993495e+208, Weights: [[-5.51502680e+199  6.84350731e+203  2.56484667e+201]\n",
      " [ 6.54306854e+202  6.16929210e+206  2.46858213e+204]\n",
      " [-4.27663487e+207 -5.60881029e+211 -2.76345291e+209]], State: [-8.08824704e-03  9.97246425e+01  5.22288317e-01]\n",
      "Target: 4.98657723566341e+211, Q-value: -5.606873613676237e+213, Action: 2, State: [1.54547498e-02 9.99623046e+01 6.42395690e-01], Reward: 0, Next state: [1.13716364e-02 1.00217460e+02 9.99673660e-01], Next Q-values: [np.float64(5.540641372959344e+211), np.float64(6.182954688578853e+208), np.float64(-5.621283500830116e+213)]\n",
      "Error: 5.656739386032871e+213, Weights: [[-4.48379638e+205  5.52833009e+209  2.89535377e+207]\n",
      " [ 6.54306854e+202  6.16929210e+206  2.46858213e+204]\n",
      " [-4.27663487e+207 -5.60881029e+211 -2.76345291e+209]], State: [1.54547498e-02 9.99623046e+01 6.42395690e-01]\n",
      "Target: 5.100172783480026e+216, Q-value: 5.540641372959344e+211, Action: 0, State: [1.13716364e-02 1.00217460e+02 9.99673660e-01], Reward: -214.22216185033136, Next state: [-2.10274440e-02  1.00310218e+02  9.26420547e-01], Next Q-values: [np.float64(5.545748271633607e+211), np.float64(6.188658899121965e+208), np.float64(5.66685864831114e+216)]\n",
      "Error: 5.1001173770662964e+216, Weights: [[-4.48379638e+205  5.52833009e+209  2.89535377e+207]\n",
      " [ 6.54306854e+202  6.16929210e+206  2.46858213e+204]\n",
      " [ 8.73807257e+210  5.64899825e+214  3.63110155e+212]], State: [1.13716364e-02 1.00217460e+02 9.99673660e-01]\n",
      "Target: 4.610116420340964e+219, Q-value: 5.66685864831114e+216, Action: 2, State: [-2.10274440e-02  1.00310218e+02  9.26420547e-01], Reward: 0, Next state: [-2.37997390e-03  1.00208239e+02  9.80586944e-01], Next Q-values: [np.float64(5.122351578156627e+219), np.float64(6.182380998926366e+208), np.float64(5.661117677417377e+216)]\n",
      "Error: 4.604449561692653e+219, Weights: [[5.79966802e+213 5.11120814e+217 5.09845303e+215]\n",
      " [6.54306854e+202 6.16929210e+206 2.46858213e+204]\n",
      " [8.73807257e+210 5.64899825e+214 3.63110155e+212]], State: [-2.10274440e-02  1.00310218e+02  9.26420547e-01]\n",
      "Target: 4.186515697562036e+222, Q-value: 6.182380998926366e+208, Action: 1, State: [-2.37997390e-03  1.00208239e+02  9.80586944e-01], Reward: -1, Next state: [2.19243025e-02 1.00704321e+02 9.71826083e-01], Next Q-values: [np.float64(5.1477030529678116e+219), np.float64(6.2129837634118e+208), np.float64(4.651684108402262e+222)]\n",
      "Error: 4.186515697561974e+222, Weights: [[ 5.79966802e+213  5.11120814e+217  5.09845303e+215]\n",
      " [ 6.54306854e+202  6.16929210e+206  2.46858213e+204]\n",
      " [-9.68197180e+216  4.61873903e+220  4.26566031e+218]], State: [-2.37997390e-03  1.00208239e+02  9.80586944e-01]\n",
      "Target: 3.792553418996377e+225, Q-value: 4.225180479598683e+225, Action: 1, State: [2.19243025e-02 1.00704321e+02 9.71826083e-01], Reward: -1, Next state: [-2.25462667e-02  1.00435287e+02  1.10413251e+00], Next Q-values: [np.float64(5.134019374471956e+219), np.float64(4.213948243329308e+225), np.float64(4.639315008254772e+222)]\n",
      "Error: -4.326270606023059e+224, Weights: [[ 5.79966802e+213  5.11120814e+217  5.09845303e+215]\n",
      " [-9.96379808e+218  4.19523364e+223  4.10524263e+221]\n",
      " [-9.68197180e+216  4.61873903e+220  4.26566031e+218]], State: [2.19243025e-02 1.00704321e+02 9.71826083e-01]\n",
      "Target: 4.1540700677611076e+222, Q-value: -4.3340302897136545e+227, Action: 1, State: [-2.25462667e-02  1.00435287e+02  1.10413251e+00], Reward: -1, Next state: [-6.33956347e-04  9.99245546e+01  8.88491540e-01], Next Q-values: [np.float64(5.107804955749941e+219), np.float64(-4.3119036881103765e+227), np.float64(4.615633408623453e+222)]\n",
      "Error: 4.3340718304143325e+227, Weights: [[ 5.79966802e+213  5.11120814e+217  5.09845303e+215]\n",
      " [-9.49501034e+221 -4.31478910e+225 -4.16333019e+223]\n",
      " [-9.68197180e+216  4.61873903e+220  4.26566031e+218]], State: [-2.25462667e-02  1.00435287e+02  1.10413251e+00]\n",
      "Target: 3.908061968181398e+230, Q-value: 5.107804955749941e+219, Action: 0, State: [-6.33956347e-04  9.99245546e+01  8.88491540e-01], Reward: -16.39604250513713, Next state: [1.01822733e-04 9.98442891e+01 9.19557468e-01], Next Q-values: [np.float64(5.103718261254092e+219), np.float64(4.342291075757109e+230), np.float64(4.611939398459915e+222)]\n",
      "Error: 3.90806196813032e+230, Weights: [[ 5.79966802e+213  5.11120814e+217  5.09845303e+215]\n",
      " [-9.78120896e+224  4.34862270e+228  4.78122627e+226]\n",
      " [-9.68197180e+216  4.61873903e+220  4.26566031e+218]], State: [-6.33956347e-04  9.99245546e+01  8.88491540e-01]\n",
      "Target: 3.519460981704159e+233, Q-value: 4.611939398459915e+222, Action: 2, State: [1.01822733e-04 9.98442891e+01 9.19557468e-01], Reward: 0, Next state: [1.60055010e-02 1.00129475e+02 9.86557753e-01], Next Q-values: [np.float64(3.91051220189351e+233), np.float64(4.354724598915674e+230), np.float64(4.625139801689182e+222)]\n",
      "Error: 3.51946098165804e+233, Weights: [[-2.47754069e+226  3.90511351e+231  3.47228000e+229]\n",
      " [-9.78120896e+224  4.34862270e+228  4.78122627e+226]\n",
      " [-9.68197180e+216  4.61873903e+220  4.26566031e+218]], State: [1.01822733e-04 9.98442891e+01 9.19557468e-01]\n",
      "Target: 3.1635263890661074e+236, Q-value: 4.354724598915674e+230, Action: 1, State: [1.60055010e-02 1.00129475e+02 9.86557753e-01], Reward: -1, Next state: [2.17143013e-03 1.00022206e+02 8.28757241e-01], Next Q-values: [np.float64(3.9062684465358266e+233), np.float64(4.3499845734970166e+230), np.float64(3.515029321184564e+236)]\n",
      "Error: 3.1635220343415086e+236, Weights: [[-2.47754069e+226  3.90511351e+231  3.47228000e+229]\n",
      " [-9.78120896e+224  4.34862270e+228  4.78122627e+226]\n",
      " [ 3.58361137e+228  3.51398080e+234  3.23634663e+232]], State: [1.60055010e-02 1.00129475e+02 9.86557753e-01]\n",
      "Target: 2.8564268472171675e+239, Q-value: 3.9062684465358266e+233, Action: 0, State: [2.17143013e-03 1.00022206e+02 8.28757241e-01], Reward: -70.87178439478095, Next state: [-9.17381946e-03  1.00187861e+02  7.65555187e-01], Next Q-values: [np.float64(3.9127155350310357e+233), np.float64(3.173807608019075e+239), np.float64(3.520829965161196e+236)]\n",
      "Error: 2.856422940948721e+239, Weights: [[-2.47754069e+226  3.90511351e+231  3.47228000e+229]\n",
      " [ 5.06337548e+233  3.16761800e+237  3.12099719e+235]\n",
      " [ 3.58361137e+228  3.51398080e+234  3.23634663e+232]], State: [2.17143013e-03 1.00022206e+02 8.28757241e-01]\n",
      "Target: 2.5824580678702377e+242, Q-value: 3.520829965161196e+236, Action: 2, State: [-9.17381946e-03  1.00187861e+02  7.65555187e-01], Reward: 0, Next state: [3.02181550e-03 1.00426684e+02 6.33625927e-01], Next Q-values: [np.float64(2.869397853189153e+242), np.float64(3.181331496195997e+239), np.float64(3.5291794643836777e+236)]\n",
      "Error: 2.582454547040273e+242, Weights: [[6.20252284e+235 2.85705724e+240 2.36728120e+238]\n",
      " [5.06337548e+233 3.16761800e+237 3.12099719e+235]\n",
      " [3.58361137e+228 3.51398080e+234 3.23634663e+232]], State: [-9.17381946e-03  1.00187861e+02  7.65555187e-01]\n",
      "Target: 2.3405129127789337e+245, Q-value: 3.181331496195997e+239, Action: 1, State: [3.02181550e-03 1.00426684e+02 6.33625927e-01], Reward: -1, Next state: [-7.69236243e-03  1.00508841e+02  4.98915126e-01], Next Q-values: [np.float64(2.8717132115705165e+242), np.float64(3.1838917990874545e+239), np.float64(2.600569903087704e+245)]\n",
      "Error: 2.3405097314474374e+245, Weights: [[ 6.20252284e+235  2.85705724e+240  2.36728120e+238]\n",
      " [ 5.06337548e+233  3.16761800e+237  3.12099719e+235]\n",
      " [-2.36909718e+239  2.58730598e+243  1.97701148e+241]], State: [3.02181550e-03 1.00426684e+02 6.33625927e-01]\n",
      "Target: 2.1203463142863926e+248, Q-value: 2.362530588739052e+248, Action: 1, State: [-7.69236243e-03  1.00508841e+02  4.98915126e-01], Reward: -1, Next state: [-2.25774516e-03  1.00227980e+02  5.75658164e-01], Next Q-values: [np.float64(2.86370702635175e+242), np.float64(2.355940349207103e+248), np.float64(2.59331833230006e+245)]\n",
      "Error: -2.4218427445265916e+247, Weights: [[ 6.20252284e+235  2.85705724e+240  2.36728120e+238]\n",
      " [ 7.07258863e+241  2.35049632e+246  1.48300765e+244]\n",
      " [-2.36909718e+239  2.58730598e+243  1.97701148e+241]], State: [-7.69236243e-03  1.00508841e+02  4.98915126e-01]\n",
      "Target: 2.3332403448926414e+245, Q-value: 2.59331833230006e+245, Action: 2, State: [-2.25774516e-03  1.00227980e+02  5.75658164e-01], Reward: 0, Next state: [1.47218802e-02 1.00196312e+02 5.26731733e-01], Next Q-values: [np.float64(2.8627906827281785e+242), np.float64(-2.415456352781586e+250), np.float64(2.592489272102935e+245)]\n",
      "Error: -2.600779874074187e+244, Weights: [[ 6.20252284e+235  2.85705724e+240  2.36728120e+238]\n",
      " [ 1.87004180e+244 -2.41066110e+248 -1.19346390e+246]\n",
      " [-2.36909718e+239  2.58730598e+243  1.97701148e+241]], State: [-2.25774516e-03  1.00227980e+02  5.75658164e-01]\n",
      "Target: 2.58069154498872e+242, Q-value: -2.415456352781586e+250, Action: 1, State: [1.47218802e-02 1.00196312e+02 5.26731733e-01], Reward: -1, Next state: [3.88907855e-04 1.00358072e+02 6.23032138e-01], Next Q-values: [np.float64(2.8674350499874666e+242), np.float64(-2.4193673609137146e+250), np.float64(-2.590169364714595e+247)]\n",
      "Error: 2.4154563785885016e+250, Weights: [[ 6.20252284e+235  2.85705724e+240  2.36728120e+238]\n",
      " [ 1.87004180e+244 -2.41066110e+248 -1.19346390e+246]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [1.47218802e-02 1.00196312e+02 5.26731733e-01]\n",
      "Target: 2.1841627572279343e+253, Q-value: 2.8674350499874666e+242, Action: 0, State: [3.88907855e-04 1.00358072e+02 6.23032138e-01], Reward: 6.676729975397677, Next state: [-4.34750805e-03  1.00371425e+02  6.27016687e-01], Next Q-values: [np.float64(2.867817506298656e+242), np.float64(2.426847508031038e+253), np.float64(-2.5905145869675778e+247)]\n",
      "Error: 2.18416275719926e+253, Weights: [[ 6.20252284e+235  2.85705724e+240  2.36728120e+238]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [3.88907855e-04 1.00358072e+02 6.23032138e-01]\n",
      "Target: 1.9868699608827636e+256, Q-value: 2.2002105413722886e+256, Action: 0, State: [-4.34750805e-03  1.00371425e+02  6.27016687e-01], Reward: 0, Next state: [8.47393284e-03 1.00709892e+02 6.53530115e-01], Next Q-values: [np.float64(2.2076332898697373e+256), np.float64(2.435034334777827e+253), np.float64(-2.5992537731180456e+247)]\n",
      "Error: -2.1334058048952497e+255, Weights: [[ 8.49438052e+248  2.19198363e+254  1.36080359e+252]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [-4.34750805e-03  1.00371425e+02  6.27016687e-01]\n",
      "Target: 2.1931254319208054e+253, Q-value: -2.134542034456438e+258, Action: 0, State: [8.47393284e-03 1.00709892e+02 6.53530115e-01], Reward: 0, Next state: [-1.52575380e-02  1.00783863e+02  5.22371702e-01], Next Q-values: [np.float64(-2.1360924346154568e+258), np.float64(2.4368060354675614e+253), np.float64(-2.601143474291959e+247)]\n",
      "Error: 2.1345639657107572e+258, Weights: [[ 9.28349329e+251 -2.11940998e+256 -1.32407300e+254]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [8.47393284e-03 1.00709892e+02 6.53530115e-01]\n",
      "Target: 1.9446547484135747e+261, Q-value: 2.164504663383586e+261, Action: 0, State: [-1.52575380e-02  1.00783863e+02  5.22371702e-01], Reward: 0, Next state: [2.14510400e-03 1.00607666e+02 5.71252059e-01], Next Q-values: [np.float64(2.1607274982373053e+261), np.float64(2.4325522343342484e+253), np.float64(-2.596603322682435e+247)]\n",
      "Error: -2.1984991497001118e+260, Weights: [[ 1.80974352e+255  2.14759766e+259  1.39367776e+257]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [-1.52575380e-02  1.00783863e+02  5.22371702e-01]\n",
      "Target: 2.1844616156934444e+253, Q-value: -2.2076549462580884e+263, Action: 0, State: [2.14510400e-03 1.00607666e+02 5.71252059e-01], Reward: 0, Next state: [-1.90896342e-03  1.00385395e+02  5.82186688e-01], Next Q-values: [np.float64(-2.202779008208661e+263), np.float64(2.4271795729927158e+253), np.float64(-2.5908684942847412e+247)]\n",
      "Error: 2.2076549464765345e+263, Weights: [[ 3.37246587e+257 -2.19425640e+261 -1.13449696e+259]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [2.14510400e-03 1.00607666e+02 5.71252059e-01]\n",
      "Target: 1.9987185008717112e+266, Q-value: 2.2275006468543491e+266, Action: 0, State: [-1.90896342e-03  1.00385395e+02  5.82186688e-01], Reward: 0, Next state: [-8.44078564e-03  1.00082297e+02  7.65269886e-01], Next Q-values: [np.float64(2.2207983343019013e+266), np.float64(2.4198745455426426e+253), np.float64(-2.5830730729985077e+247)]\n",
      "Error: -2.2878214598263793e+265, Weights: [[ 4.76937411e+259  2.21887586e+264  1.25999294e+262]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [-1.90896342e-03  1.00385395e+02  5.82186688e-01]\n",
      "Target: 2.1746673140263386e+253, Q-value: -2.2764226147784202e+268, Action: 0, State: [-8.44078564e-03  1.00082297e+02  7.65269886e-01], Reward: 0, Next state: [1.64969222e-02 9.99355959e+01 5.23694517e-01], Next Q-values: [np.float64(-2.27305409728219e+268), np.float64(2.4162970155848206e+253), np.float64(-2.5792512635309047e+247)]\n",
      "Error: 2.2764226147784224e+268, Weights: [[ 4.41506122e+261 -2.27444985e+266 -1.31933927e+264]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [-8.44078564e-03  1.00082297e+02  7.65269886e-01]\n",
      "Target: 2.0504402787037558e+271, Q-value: -2.5792512635309047e+247, Action: 2, State: [1.64969222e-02 9.99355959e+01 5.23694517e-01], Reward: 0, Next state: [-2.16762245e-04  1.00094065e+02  6.00028227e-01], Next Q-values: [np.float64(2.2782669763375062e+271), np.float64(2.4201381086959415e+253), np.float64(-2.583352381952714e+247)]\n",
      "Error: 2.0504402787037558e+271, Weights: [[-1.92103803e+265  2.27602158e+269  1.74075834e+267]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 5.63498846e+240 -2.58083607e+245 -1.47739005e+243]], State: [1.64969222e-02 9.99355959e+01 5.23694517e-01]\n",
      "Target: 1.8443109996410433e+274, Q-value: 2.2782669763375062e+271, Action: 0, State: [-2.16762245e-04  1.00094065e+02  6.00028227e-01], Reward: -103.67984400859598, Next state: [-1.02977896e-02  1.00002320e+02  6.26065001e-01], Next Q-values: [np.float64(2.2761833914512582e+271), np.float64(2.4179231825278458e+253), np.float64(2.0492344440456034e+274)]\n",
      "Error: 1.8420327326647058e+274, Weights: [[-1.92103803e+265  2.27602158e+269  1.74075834e+267]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 3.38259537e+268  2.04911971e+272  1.07380433e+270]], State: [-2.16762245e-04  1.00094065e+02  6.00028227e-01]\n",
      "Target: 1.6652157177033425e+277, Q-value: 2.0492344440456034e+274, Action: 2, State: [-1.02977896e-02  1.00002320e+02  6.26065001e-01], Reward: 0, Next state: [1.99135754e-02 1.00345651e+02 8.95417765e-01], Next Q-values: [np.float64(1.850239686337047e+277), np.float64(2.4262585377016456e+253), np.float64(2.056298729249333e+274)]\n",
      "Error: 1.663166483259297e+277, Weights: [[-3.99302361e+269  1.84376772e+275  1.10527337e+273]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 3.38259537e+268  2.04911971e+272  1.07380433e+270]], State: [-1.02977896e-02  1.00002320e+02  6.26065001e-01]\n",
      "Target: 1.5010989706318304e+280, Q-value: 1.850239686337047e+277, Action: 0, State: [1.99135754e-02 1.00345651e+02 8.95417765e-01], Reward: -291.24829349129726, Next state: [-2.86579524e-02  1.00275153e+02  1.00081710e+00], Next Q-values: [np.float64(1.848951522385883e+277), np.float64(2.424567275582278e+253), np.float64(1.6678877451464782e+280)]\n",
      "Error: 1.4992487309454934e+280, Weights: [[-3.99302361e+269  1.84376772e+275  1.10527337e+273]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [-1.71269047e+274  1.66320712e+278  1.04125140e+276]], State: [1.99135754e-02 1.00345651e+02 8.95417765e-01]\n",
      "Target: 1.3578188018409249e+283, Q-value: 1.508706505275362e+283, Action: 0, State: [-2.86579524e-02  1.00275153e+02  1.00081710e+00], Reward: 0, Next state: [2.00625038e-02 1.00273889e+02 1.00027905e+00], Next Q-values: [np.float64(1.5086875576010276e+283), np.float64(2.4245368118696725e+253), np.float64(1.6678665773562562e+280)]\n",
      "Error: -1.5088770343443723e+282, Weights: [[ 2.98554022e+277  1.50443274e+281  1.34245505e+279]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [-1.71269047e+274  1.66320712e+278  1.04125140e+276]], State: [-2.86579524e-02  1.00275153e+02  1.00081710e+00]\n",
      "Target: 1.504710766975361e+280, Q-value: 1.6678665773562562e+280, Action: 2, State: [2.00625038e-02 1.00273889e+02 1.00027905e+00], Reward: 0, Next state: [1.18291623e-02 1.00515223e+02 1.19596797e+00], Next Q-values: [np.float64(-1.5058813344958538e+285), np.float64(2.4303966005508426e+253), np.float64(1.6719008521948456e+280)]\n",
      "Error: -1.6315581038089512e+279, Weights: [[ 4.35398803e+279 -1.49798443e+283 -1.49668538e+281]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [-1.71269047e+274  1.66320712e+278  1.04125140e+276]], State: [2.00625038e-02 1.00273889e+02 1.00027905e+00]\n",
      "Target: 2.1837962987133366e+253, Q-value: -1.6279321561107082e+282, Action: 2, State: [1.18291623e-02 1.00515223e+02 1.19596797e+00], Reward: 0, Next state: [-3.00885072e-02  1.00350783e+02  1.35083264e+00], Next Q-values: [np.float64(-1.5034414131347359e+285), np.float64(2.4264403319037073e+253), np.float64(-1.6252942020558344e+282)]\n",
      "Error: 1.6279321561107082e+282, Weights: [[ 4.35398803e+279 -1.49798443e+283 -1.49668538e+281]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [-3.29044097e+276 -1.61939469e+280 -1.62160087e+278]], State: [1.18291623e-02 1.00515223e+02 1.19596797e+00]\n",
      "Target: 1.4744116062186202e+285, Q-value: -1.5034414131347359e+285, Action: 0, State: [-3.00885072e-02  1.00350783e+02  1.35083264e+00], Reward: -100.55625331373221, Next state: [2.08464846e-02 1.00201507e+02 1.23783180e+00], Next Q-values: [np.float64(-1.50118814974314e+285), np.float64(2.422816976695353e+253), np.float64(1.638235118020689e+285)]\n",
      "Error: 2.977853019353356e+285, Weights: [[ 4.35398803e+279 -1.49798443e+283 -1.49668538e+281]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 1.92241694e+279  1.63470024e+283  1.94533312e+281]], State: [-3.00885072e-02  1.00350783e+02  1.35083264e+00]\n",
      "Target: 2.695981019662991e+288, Q-value: 2.422816976695353e+253, Action: 1, State: [2.08464846e-02 1.00201507e+02 1.23783180e+00], Reward: -1, Next state: [-1.77363618e-02  1.00276869e+02  1.15375119e+00], Next Q-values: [np.float64(2.995534466292212e+288), np.float64(2.4246282479694548e+253), np.float64(1.6394506322034234e+285)]\n",
      "Error: 2.695981019662991e+288, Weights: [[-8.95556121e+282  2.98680084e+286  4.02108437e+284]\n",
      " [ 3.55787599e+247  2.41778755e+251  1.27110406e+249]\n",
      " [ 1.92241694e+279  1.63470024e+283  1.94533312e+281]], State: [2.08464846e-02 1.00201507e+02 1.23783180e+00]\n",
      "Target: 2.4376228770118978e+291, Q-value: 2.995534466292212e+288, Action: 0, State: [-1.77363618e-02  1.00276869e+02  1.15375119e+00], Reward: 0, Next state: [1.46798111e-02 1.00247065e+02 1.14439615e+00], Next Q-values: [np.float64(2.9946402324558605e+288), np.float64(2.708469863346553e+291), np.float64(1.6389616709648545e+285)]\n",
      "Error: 2.4346273425456055e+291, Weights: [[-8.95556121e+282  2.98680084e+286  4.02108437e+284]\n",
      " [ 5.62017268e+285  2.70141362e+289  3.33717104e+287]\n",
      " [ 1.92241694e+279  1.63470024e+283  1.94533312e+281]], State: [-1.77363618e-02  1.00276869e+02  1.15375119e+00]\n",
      "Target: 2.1937790475383007e+294, Q-value: 1.6389616709648545e+285, Action: 2, State: [1.46798111e-02 1.00247065e+02 1.14439615e+00], Reward: 0, Next state: [-7.23270453e-03  9.98335820e+01  7.97655585e-01], Next Q-values: [np.float64(2.4375322750425562e+294), np.float64(2.6971841287408977e+291), np.float64(1.6321349613141441e+285)]\n",
      "Error: 2.1937790458993391e+294, Weights: [[-4.31815211e+288  2.44137107e+292  2.80895821e+290]\n",
      " [ 5.62017268e+285  2.70141362e+289  3.33717104e+287]\n",
      " [ 1.92241694e+279  1.63470024e+283  1.94533312e+281]], State: [1.46798111e-02 1.00247065e+02 1.14439615e+00]\n",
      "Target: 1.977238413054275e+297, Q-value: 2.1957394863983382e+297, Action: 2, State: [-7.23270453e-03  9.98335820e+01  7.97655585e-01], Reward: 0, Next state: [-7.24829216e-03  9.98885259e+01  7.32967233e-01], Next Q-values: [np.float64(2.438855487009565e+294), np.float64(2.6986468009485557e+291), np.float64(2.1969315700603056e+297)]\n",
      "Error: -2.185010733440632e+296, Weights: [[-4.31815211e+288  2.44137107e+292  2.80895821e+290]\n",
      " [ 5.62017268e+285  2.70141362e+289  3.33717104e+287]\n",
      " [ 3.22042620e+291  2.19919912e+295  2.51055230e+293]], State: [-7.23270453e-03  9.98335820e+01  7.97655585e-01]\n",
      "Target: 2.1914675526028854e+294, Q-value: -2.1571012579129318e+299, Action: 2, State: [-7.24829216e-03  9.98885259e+01  7.32967233e-01], Reward: 0, Next state: [1.00694839e-02 9.97310206e+01 5.68576699e-01], Next Q-values: [np.float64(2.4349639473365394e+294), np.float64(2.694337169325716e+291), np.float64(-2.1536718499104512e+299)]\n",
      "Error: 2.1571231725884577e+299, Weights: [[-4.31815211e+288  2.44137107e+292  2.80895821e+290]\n",
      " [ 5.62017268e+285  2.70141362e+289  3.33717104e+287]\n",
      " [ 1.61255796e+293 -2.15938249e+297 -1.71778049e+295]], State: [-7.24829216e-03  9.98885259e+01  7.32967233e-01]\n",
      "Target: 1.9320344183459687e+302, Q-value: 2.4349639473365394e+294, Action: 0, State: [1.00694839e-02 9.97310206e+01 5.68576699e-01], Reward: -76.35394384226686, Next state: [-1.03688034e-02  9.97238004e+01  5.76796834e-01], Next Q-values: [np.float64(2.43479007234145e+294), np.float64(2.6941447497738685e+291), np.float64(2.1467049092732984e+302)]\n",
      "Error: 1.9320343939963294e+302, Weights: [[-4.31815211e+288  2.44137107e+292  2.80895821e+290]\n",
      " [ 5.62017268e+285  2.70141362e+289  3.33717104e+287]\n",
      " [-1.56193334e+296  2.15255916e+300  1.57938282e+298]], State: [1.00694839e-02 9.97310206e+01 5.68576699e-01]\n",
      "Target: 1.7237244919648091e+305, Q-value: 2.6941447497738685e+291, Action: 1, State: [-1.03688034e-02  9.97238004e+01  5.76796834e-01], Reward: -1, Next state: [-1.50124918e-03  9.93959035e+01  4.71344175e-01], Next Q-values: [np.float64(1.9152494355164545e+305), np.float64(2.685251758448032e+291), np.float64(2.1396300670205597e+302)]\n",
      "Error: 1.7237244919647823e+305, Weights: [[ 1.94545893e+299  1.92683762e+303  1.09850974e+301]\n",
      " [ 5.62017268e+285  2.70141362e+289  3.33717104e+287]\n",
      " [-1.56193334e+296  2.15255916e+300  1.57938282e+298]], State: [-1.03688034e-02  9.97238004e+01  5.76796834e-01]\n",
      "Target: 1.540755219351752e+308, Q-value: 2.1396300670205597e+302, Action: 2, State: [-1.50124918e-03  9.93959035e+01  4.71344175e-01], Reward: 0, Next state: [1.89230167e-02 9.95877837e+01 7.29749833e-01], Next Q-values: [np.float64(1.9189750807083035e+305), np.float64(1.7119502437241689e+308), np.float64(2.1438011814822302e+302)]\n",
      "Error: 1.540753079721685e+308, Weights: [[ 1.94545893e+299  1.92683762e+303  1.09850974e+301]\n",
      " [-1.78729604e+302  1.71896357e+306  9.94238830e+303]\n",
      " [-1.56193334e+296  2.15255916e+300  1.57938282e+298]], State: [-1.50124918e-03  9.93959035e+01  4.71344175e-01]\n",
      "Target: inf, Q-value: inf, Action: 2, State: [1.89230167e-02 9.95877837e+01 7.29749833e-01], Reward: 0, Next state: [-1.03950162e-02  9.97148475e+01  6.87377764e-01], Next Q-values: [np.float64(1.9214186823375945e+305), np.float64(1.7141302639239144e+308), np.float64(inf)]\n",
      "Error: nan, Weights: [[ 1.94545893e+299  1.92683762e+303  1.09850974e+301]\n",
      " [-1.78729604e+302  1.71896357e+306  9.94238830e+303]\n",
      " [-2.31305431e+304              inf  7.26224990e+306]], State: [1.89230167e-02 9.95877837e+01 7.29749833e-01]\n",
      "Target: 1.5466711382314035e+308, Q-value: nan, Action: 2, State: [-1.03950162e-02  9.97148475e+01  6.87377764e-01], Reward: 0, Next state: [1.63688273e-02 9.99688409e+01 9.61128524e-01], Next Q-values: [np.float64(1.9263428459600787e+305), np.float64(1.7185234869237816e+308), np.float64(nan)]\n",
      "Error: nan, Weights: [[ 1.94545893e+299  1.92683762e+303  1.09850974e+301]\n",
      " [-1.78729604e+302  1.71896357e+306  9.94238830e+303]\n",
      " [             nan              nan              nan]], State: [-1.03950162e-02  9.97148475e+01  6.87377764e-01]\n",
      "Target: 1.55022044851944e+308, Q-value: 1.9263428459600787e+305, Action: 0, State: [1.63688273e-02 9.99688409e+01 9.61128524e-01], Reward: -57.25223715063947, Next state: [-1.14182847e-02  1.00198924e+02  8.46220644e-01], Next Q-values: [np.float64(1.9307635062437233e+305), np.float64(1.7224671650216e+308), np.float64(nan)]\n",
      "Error: 1.54829410567348e+308, Weights: [[ 1.94545893e+299  1.92683762e+303  1.09850974e+301]\n",
      " [-1.78729604e+302  1.71896357e+306  9.94238830e+303]\n",
      " [             nan              nan              nan]], State: [1.63688273e-02 9.99688409e+01 9.61128524e-01]\n",
      "Target: inf, Q-value: 1.7224671650216e+308, Action: 1, State: [-1.14182847e-02  1.00198924e+02  8.46220644e-01], Reward: -1, Next state: [1.13014696e-02 1.00685249e+02 6.38086129e-01], Next Q-values: [np.float64(inf), np.float64(1.7308061732287359e+308), np.float64(nan)]\n",
      "Error: inf, Weights: [[ 2.53437783e+305              inf  1.48811073e+307]\n",
      " [-1.78729604e+302  1.71896357e+306  9.94238830e+303]\n",
      " [             nan              nan              nan]], State: [-1.14182847e-02  1.00198924e+02  8.46220644e-01]\n",
      "Target: inf, Q-value: nan, Action: 2, State: [1.13014696e-02 1.00685249e+02 6.38086129e-01], Reward: 0, Next state: [9.60285314e-03 1.00991875e+02 9.17345631e-01], Next Q-values: [np.float64(inf), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[2.53437783e+305             inf 1.48811073e+307]\n",
      " [           -inf             inf             inf]\n",
      " [            nan             nan             nan]], State: [1.13014696e-02 1.00685249e+02 6.38086129e-01]\n",
      "Target: inf, Q-value: nan, Action: 2, State: [9.60285314e-03 1.00991875e+02 9.17345631e-01], Reward: 0, Next state: [-2.43218383e-02  1.01010333e+02  8.92413231e-01], Next Q-values: [np.float64(inf), np.float64(inf), np.float64(nan)]\n",
      "Error: nan, Weights: [[2.53437783e+305             inf 1.48811073e+307]\n",
      " [           -inf             inf             inf]\n",
      " [            nan             nan             nan]], State: [9.60285314e-03 1.00991875e+02 9.17345631e-01]\n",
      "Target: inf, Q-value: inf, Action: 0, State: [-2.43218383e-02  1.01010333e+02  8.92413231e-01], Reward: -212.06471027477534, Next state: [3.68448484e-03 1.00775850e+02 9.21906066e-01], Next Q-values: [np.float64(inf), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[2.53437783e+305             inf 1.48811073e+307]\n",
      " [           -inf             inf             inf]\n",
      " [            nan             nan             nan]], State: [-2.43218383e-02  1.01010333e+02  8.92413231e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.68448484e-03 1.00775850e+02 9.21906066e-01], Reward: 0, Next state: [-5.43849494e-03  1.00663872e+02  1.01355387e+00], Next Q-values: [np.float64(nan), np.float64(inf), np.float64(nan)]\n",
      "Error: nan, Weights: [[ nan  nan  nan]\n",
      " [-inf  inf  inf]\n",
      " [ nan  nan  nan]], State: [3.68448484e-03 1.00775850e+02 9.21906066e-01]\n",
      "Target: nan, Q-value: inf, Action: 1, State: [-5.43849494e-03  1.00663872e+02  1.01355387e+00], Reward: -1, Next state: [1.28411868e-02 1.00581313e+02 9.71014584e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[ nan  nan  nan]\n",
      " [-inf  inf  inf]\n",
      " [ nan  nan  nan]], State: [-5.43849494e-03  1.00663872e+02  1.01355387e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.28411868e-02 1.00581313e+02 9.71014584e-01], Reward: -62.83171409491217, Next state: [-1.89038129e-02  9.99225407e+01  6.29801884e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.28411868e-02 1.00581313e+02 9.71014584e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.89038129e-02  9.99225407e+01  6.29801884e-01], Reward: 0, Next state: [1.79618301e-02 1.00117173e+02 7.14283249e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.89038129e-02  9.99225407e+01  6.29801884e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.79618301e-02 1.00117173e+02 7.14283249e-01], Reward: 0, Next state: [-1.61814865e-02  9.99120317e+01  8.04680244e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.79618301e-02 1.00117173e+02 7.14283249e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.61814865e-02  9.99120317e+01  8.04680244e-01], Reward: 175.82721982800678, Next state: [1.77304024e-02 1.00167524e+02 8.79569237e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.61814865e-02  9.99120317e+01  8.04680244e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.77304024e-02 1.00167524e+02 8.79569237e-01], Reward: 0, Next state: [-3.07768055e-02  9.95458658e+01  1.17243754e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.77304024e-02 1.00167524e+02 8.79569237e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-3.07768055e-02  9.95458658e+01  1.17243754e+00], Reward: 414.3211471575043, Next state: [4.23558144e-02 1.00134432e+02 1.46312362e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.07768055e-02  9.95458658e+01  1.17243754e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [4.23558144e-02 1.00134432e+02 1.46312362e+00], Reward: -1, Next state: [-1.68458454e-02  1.00023756e+02  1.42927037e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.23558144e-02 1.00134432e+02 1.46312362e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.68458454e-02  1.00023756e+02  1.42927037e+00], Reward: 0, Next state: [-5.19309671e-03  1.00135176e+02  1.37897401e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.68458454e-02  1.00023756e+02  1.42927037e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-5.19309671e-03  1.00135176e+02  1.37897401e+00], Reward: -1, Next state: [2.01680424e-04 9.98989640e+01 1.32342602e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-5.19309671e-03  1.00135176e+02  1.37897401e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.01680424e-04 9.98989640e+01 1.32342602e+00], Reward: -1, Next state: [-2.79290526e-03  1.00228269e+02  9.03030539e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.01680424e-04 9.98989640e+01 1.32342602e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.79290526e-03  1.00228269e+02  9.03030539e-01], Reward: -1, Next state: [-2.70241527e-03  9.96751717e+01  3.47623082e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.79290526e-03  1.00228269e+02  9.03030539e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.70241527e-03  9.96751717e+01  3.47623082e-01], Reward: -1, Next state: [1.55177206e-02 9.97734652e+01 5.21019937e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.70241527e-03  9.96751717e+01  3.47623082e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.55177206e-02 9.97734652e+01 5.21019937e-01], Reward: -1, Next state: [-8.71715339e-03  9.98002483e+01  5.21239856e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.55177206e-02 9.97734652e+01 5.21019937e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-8.71715339e-03  9.98002483e+01  5.21239856e-01], Reward: 207.4117861529345, Next state: [1.94295976e-02 1.00211049e+02 9.49076475e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.71715339e-03  9.98002483e+01  5.21239856e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.94295976e-02 1.00211049e+02 9.49076475e-01], Reward: 0, Next state: [-1.11675892e-02  1.00450197e+02  8.79216936e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.94295976e-02 1.00211049e+02 9.49076475e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.11675892e-02  1.00450197e+02  8.79216936e-01], Reward: -1, Next state: [-7.84071865e-03  1.00585253e+02  7.12360006e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.11675892e-02  1.00450197e+02  8.79216936e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-7.84071865e-03  1.00585253e+02  7.12360006e-01], Reward: -117.06098328868677, Next state: [-3.81839695e-03  1.00336177e+02  8.24866803e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.84071865e-03  1.00585253e+02  7.12360006e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.81839695e-03  1.00336177e+02  8.24866803e-01], Reward: -1, Next state: [1.42959828e-02 1.00547191e+02 8.10400102e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.81839695e-03  1.00336177e+02  8.24866803e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.42959828e-02 1.00547191e+02 8.10400102e-01], Reward: 0, Next state: [-3.25563728e-03  1.00304457e+02  5.33906595e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.42959828e-02 1.00547191e+02 8.10400102e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.25563728e-03  1.00304457e+02  5.33906595e-01], Reward: -1, Next state: [-3.01524238e-03  1.00228435e+02  5.03879227e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.25563728e-03  1.00304457e+02  5.33906595e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.01524238e-03  1.00228435e+02  5.03879227e-01], Reward: -1, Next state: [1.44446413e-02 1.00599969e+02 7.35755406e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.01524238e-03  1.00228435e+02  5.03879227e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.44446413e-02 1.00599969e+02 7.35755406e-01], Reward: 0, Next state: [-1.39041244e-02  1.00764881e+02  5.33201893e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.44446413e-02 1.00599969e+02 7.35755406e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.39041244e-02  1.00764881e+02  5.33201893e-01], Reward: -1, Next state: [-7.69772406e-03  1.00490889e+02  7.09460449e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.39041244e-02  1.00764881e+02  5.33201893e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-7.69772406e-03  1.00490889e+02  7.09460449e-01], Reward: -1, Next state: [-1.45613019e-03  1.00253614e+02  8.27071365e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.69772406e-03  1.00490889e+02  7.09460449e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.45613019e-03  1.00253614e+02  8.27071365e-01], Reward: -1, Next state: [1.14461335e-02 1.00304542e+02 8.35012476e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.45613019e-03  1.00253614e+02  8.27071365e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.14461335e-02 1.00304542e+02 8.35012476e-01], Reward: 0, Next state: [-1.79330520e-02  9.97051816e+01  6.52388183e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.14461335e-02 1.00304542e+02 8.35012476e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.79330520e-02  9.97051816e+01  6.52388183e-01], Reward: -1, Next state: [5.29488082e-03 9.94932696e+01 5.88736214e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.79330520e-02  9.97051816e+01  6.52388183e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [5.29488082e-03 9.94932696e+01 5.88736214e-01], Reward: 0, Next state: [5.06099322e-03 9.95362644e+01 5.98580241e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [5.29488082e-03 9.94932696e+01 5.88736214e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [5.06099322e-03 9.95362644e+01 5.98580241e-01], Reward: 0, Next state: [-9.65964625e-04  9.95889762e+01  5.95703816e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [5.06099322e-03 9.95362644e+01 5.98580241e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-9.65964625e-04  9.95889762e+01  5.95703816e-01], Reward: -1, Next state: [1.02638678e-02 9.96187259e+01 6.44010538e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-9.65964625e-04  9.95889762e+01  5.95703816e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.02638678e-02 9.96187259e+01 6.44010538e-01], Reward: 73.27595078893268, Next state: [-2.88182902e-03  9.99510278e+01  5.17526475e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.02638678e-02 9.96187259e+01 6.44010538e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.88182902e-03  9.99510278e+01  5.17526475e-01], Reward: -1, Next state: [3.99770016e-03 1.00259043e+02 4.68052331e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.88182902e-03  9.99510278e+01  5.17526475e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [3.99770016e-03 1.00259043e+02 4.68052331e-01], Reward: -1, Next state: [-8.54302755e-03  1.00294372e+02  4.34368291e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.99770016e-03 1.00259043e+02 4.68052331e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-8.54302755e-03  1.00294372e+02  4.34368291e-01], Reward: 0, Next state: [4.49638425e-03 1.00438842e+02 2.98983311e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.54302755e-03  1.00294372e+02  4.34368291e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [4.49638425e-03 1.00438842e+02 2.98983311e-01], Reward: 0, Next state: [1.33577879e-03 1.00405547e+02 2.78301195e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.49638425e-03 1.00438842e+02 2.98983311e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.33577879e-03 1.00405547e+02 2.78301195e-01], Reward: -1, Next state: [8.35428633e-03 1.00598235e+02 4.70890069e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.33577879e-03 1.00405547e+02 2.78301195e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [8.35428633e-03 1.00598235e+02 4.70890069e-01], Reward: -1, Next state: [-1.22306867e-02  1.00462717e+02  4.91545731e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.35428633e-03 1.00598235e+02 4.70890069e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.22306867e-02  1.00462717e+02  4.91545731e-01], Reward: -1, Next state: [9.01321557e-03 1.00679898e+02 4.48317325e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.22306867e-02  1.00462717e+02  4.91545731e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [9.01321557e-03 1.00679898e+02 4.48317325e-01], Reward: -91.26875794502212, Next state: [-1.40085702e-02  1.00524179e+02  6.24568237e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.01321557e-03 1.00679898e+02 4.48317325e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.40085702e-02  1.00524179e+02  6.24568237e-01], Reward: -1, Next state: [6.23022085e-03 1.00465755e+02 6.35949215e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.40085702e-02  1.00524179e+02  6.24568237e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [6.23022085e-03 1.00465755e+02 6.35949215e-01], Reward: -1, Next state: [-1.24058508e-02  9.99907002e+01  6.77786719e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.23022085e-03 1.00465755e+02 6.35949215e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.24058508e-02  9.99907002e+01  6.77786719e-01], Reward: -1, Next state: [-4.11884230e-03  9.96820426e+01  8.72743743e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.24058508e-02  9.99907002e+01  6.77786719e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.11884230e-03  9.96820426e+01  8.72743743e-01], Reward: -1, Next state: [1.70679279e-02 9.95294018e+01 6.67984870e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.11884230e-03  9.96820426e+01  8.72743743e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.70679279e-02 9.95294018e+01 6.67984870e-01], Reward: 0, Next state: [6.59981478e-03 9.97921283e+01 8.73113033e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.70679279e-02 9.95294018e+01 6.67984870e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [6.59981478e-03 9.97921283e+01 8.73113033e-01], Reward: -1, Next state: [-1.19720924e-02  9.96890992e+01  8.45787362e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.59981478e-03 9.97921283e+01 8.73113033e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.19720924e-02  9.96890992e+01  8.45787362e-01], Reward: 0, Next state: [-4.28619003e-03  9.97492720e+01  8.03014491e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.19720924e-02  9.96890992e+01  8.45787362e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-4.28619003e-03  9.97492720e+01  8.03014491e-01], Reward: 146.37539385256133, Next state: [1.47431585e-02 1.00183735e+02 6.16076275e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.28619003e-03  9.97492720e+01  8.03014491e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.47431585e-02 1.00183735e+02 6.16076275e-01], Reward: 0, Next state: [-8.08080076e-04  1.00265420e+02  6.46756971e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.47431585e-02 1.00183735e+02 6.16076275e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-8.08080076e-04  1.00265420e+02  6.46756971e-01], Reward: 0, Next state: [-2.96821433e-03  1.00155010e+02  5.68056593e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.08080076e-04  1.00265420e+02  6.46756971e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.96821433e-03  1.00155010e+02  5.68056593e-01], Reward: -1, Next state: [1.15326121e-02 1.00517742e+02 7.25853061e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.96821433e-03  1.00155010e+02  5.68056593e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.15326121e-02 1.00517742e+02 7.25853061e-01], Reward: 0, Next state: [-1.17483186e-02  1.00727401e+02  4.30342674e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.15326121e-02 1.00517742e+02 7.25853061e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.17483186e-02  1.00727401e+02  4.30342674e-01], Reward: 0, Next state: [1.91031632e-03 1.00682643e+02 4.37517382e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.17483186e-02  1.00727401e+02  4.30342674e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.91031632e-03 1.00682643e+02 4.37517382e-01], Reward: 0, Next state: [-1.54019038e-02  1.00344516e+02  8.12422717e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.91031632e-03 1.00682643e+02 4.37517382e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.54019038e-02  1.00344516e+02  8.12422717e-01], Reward: 0, Next state: [9.39422201e-03 1.00252107e+02 8.30665116e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.54019038e-02  1.00344516e+02  8.12422717e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [9.39422201e-03 1.00252107e+02 8.30665116e-01], Reward: 0, Next state: [9.31099107e-03 1.00114243e+02 6.44325844e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.39422201e-03 1.00252107e+02 8.30665116e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [9.31099107e-03 1.00114243e+02 6.44325844e-01], Reward: 103.35222134291939, Next state: [1.02450838e-03 1.00235589e+02 7.25864365e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.31099107e-03 1.00114243e+02 6.44325844e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.02450838e-03 1.00235589e+02 7.25864365e-01], Reward: 0, Next state: [-6.88672749e-03  1.00179574e+02  7.12157038e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.02450838e-03 1.00235589e+02 7.25864365e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-6.88672749e-03  1.00179574e+02  7.12157038e-01], Reward: 0, Next state: [-7.96502544e-03  1.00273522e+02  5.62313810e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-6.88672749e-03  1.00179574e+02  7.12157038e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-7.96502544e-03  1.00273522e+02  5.62313810e-01], Reward: 6.775426936779638, Next state: [6.81323683e-04 1.00195062e+02 6.31373713e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.96502544e-03  1.00273522e+02  5.62313810e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.81323683e-04 1.00195062e+02 6.31373713e-01], Reward: 0, Next state: [1.98589763e-02 1.00325803e+02 7.96506479e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.81323683e-04 1.00195062e+02 6.31373713e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.98589763e-02 1.00325803e+02 7.96506479e-01], Reward: 0, Next state: [-2.37144588e-02  9.99545309e+01  8.54834420e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.98589763e-02 1.00325803e+02 7.96506479e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.37144588e-02  9.99545309e+01  8.54834420e-01], Reward: -1, Next state: [1.83370465e-02 1.00085662e+02 9.35578393e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.37144588e-02  9.99545309e+01  8.54834420e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.83370465e-02 1.00085662e+02 9.35578393e-01], Reward: 193.93375375626647, Next state: [1.21370020e-03 1.00400973e+02 9.32206661e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.83370465e-02 1.00085662e+02 9.35578393e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.21370020e-03 1.00400973e+02 9.32206661e-01], Reward: 0, Next state: [-4.01531725e-03  1.00621607e+02  8.19638546e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.21370020e-03 1.00400973e+02 9.32206661e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.01531725e-03  1.00621607e+02  8.19638546e-01], Reward: -1, Next state: [-1.72295507e-02  1.00100282e+02  9.24395361e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.01531725e-03  1.00621607e+02  8.19638546e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.72295507e-02  1.00100282e+02  9.24395361e-01], Reward: 0, Next state: [2.43768295e-03 1.00108518e+02 9.15428633e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.72295507e-02  1.00100282e+02  9.24395361e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.43768295e-03 1.00108518e+02 9.15428633e-01], Reward: 0, Next state: [9.66718943e-03 9.99450281e+01 8.28495829e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.43768295e-03 1.00108518e+02 9.15428633e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [9.66718943e-03 9.99450281e+01 8.28495829e-01], Reward: 0, Next state: [3.74871020e-03 9.98320810e+01 7.03022106e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.66718943e-03 9.99450281e+01 8.28495829e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [3.74871020e-03 9.98320810e+01 7.03022106e-01], Reward: -62.2660757125729, Next state: [-4.61450877e-03  9.97075488e+01  6.00860185e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.74871020e-03 9.98320810e+01 7.03022106e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-4.61450877e-03  9.97075488e+01  6.00860185e-01], Reward: 0, Next state: [-4.60594260e-03  9.98376176e+01  4.62659984e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.61450877e-03  9.97075488e+01  6.00860185e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.60594260e-03  9.98376176e+01  4.62659984e-01], Reward: -1, Next state: [8.74617085e-03 1.00093584e+02 3.32451737e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.60594260e-03  9.98376176e+01  4.62659984e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [8.74617085e-03 1.00093584e+02 3.32451737e-01], Reward: -1, Next state: [6.02496343e-03 1.00278886e+02 4.93423200e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.74617085e-03 1.00093584e+02 3.32451737e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [6.02496343e-03 1.00278886e+02 4.93423200e-01], Reward: -1, Next state: [-4.17743037e-03  1.00304762e+02  5.05327486e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.02496343e-03 1.00278886e+02 4.93423200e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/femiojo/code/projects/rl-for-trading/trading_agent_linear_approx/trading_agent.py:36: RuntimeWarning: overflow encountered in multiply\n",
      "  self.weights[action] += self.alpha * error * state\n",
      "/home/femiojo/code/projects/rl-for-trading/trading_agent_linear_approx/trading_agent.py:34: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  error = target - self._get_q_value(state, action)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: nan, Q-value: nan, Action: 2, State: [-4.17743037e-03  1.00304762e+02  5.05327486e-01], Reward: 0, Next state: [2.44082091e-03 1.00472452e+02 5.13208259e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.17743037e-03  1.00304762e+02  5.05327486e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.44082091e-03 1.00472452e+02 5.13208259e-01], Reward: 0, Next state: [-3.59677644e-03  1.00659721e+02  2.27393411e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.44082091e-03 1.00472452e+02 5.13208259e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.59677644e-03  1.00659721e+02  2.27393411e-01], Reward: -1, Next state: [-8.89768318e-03  1.00494096e+02  4.96367459e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.59677644e-03  1.00659721e+02  2.27393411e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-8.89768318e-03  1.00494096e+02  4.96367459e-01], Reward: 0, Next state: [-1.55580356e-03  1.00176501e+02  5.68583655e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.89768318e-03  1.00494096e+02  4.96367459e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.55580356e-03  1.00176501e+02  5.68583655e-01], Reward: -1, Next state: [1.20707586e-02 1.00183313e+02 5.73633516e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.55580356e-03  1.00176501e+02  5.68583655e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.20707586e-02 1.00183313e+02 5.73633516e-01], Reward: -1, Next state: [-2.21377266e-02  9.96955215e+01  8.05107605e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.20707586e-02 1.00183313e+02 5.73633516e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.21377266e-02  9.96955215e+01  8.05107605e-01], Reward: -1, Next state: [1.18247308e-02 9.95129574e+01 7.06443698e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.21377266e-02  9.96955215e+01  8.05107605e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.18247308e-02 9.95129574e+01 7.06443698e-01], Reward: 0, Next state: [6.72409714e-03 9.96430670e+01 7.63519221e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.18247308e-02 9.95129574e+01 7.06443698e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [6.72409714e-03 9.96430670e+01 7.63519221e-01], Reward: 0, Next state: [1.46315521e-02 1.00097452e+02 1.09832672e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.72409714e-03 9.96430670e+01 7.63519221e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.46315521e-02 1.00097452e+02 1.09832672e+00], Reward: 0, Next state: [-8.91889558e-03  1.00130425e+02  1.11586341e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.46315521e-02 1.00097452e+02 1.09832672e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-8.91889558e-03  1.00130425e+02  1.11586341e+00], Reward: 0, Next state: [-5.35741485e-03  1.00500909e+02  7.11804623e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.91889558e-03  1.00130425e+02  1.11586341e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-5.35741485e-03  1.00500909e+02  7.11804623e-01], Reward: 29.09199497618573, Next state: [-4.20527765e-03  1.00554388e+02  6.45809419e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-5.35741485e-03  1.00500909e+02  7.11804623e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.20527765e-03  1.00554388e+02  6.45809419e-01], Reward: -1, Next state: [9.23600612e-03 1.00658377e+02 6.26071123e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.20527765e-03  1.00554388e+02  6.45809419e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [9.23600612e-03 1.00658377e+02 6.26071123e-01], Reward: -1, Next state: [-1.66161799e-02  1.00134272e+02  6.38033639e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.23600612e-03 1.00658377e+02 6.26071123e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.66161799e-02  1.00134272e+02  6.38033639e-01], Reward: 0, Next state: [2.03143101e-02 1.00194078e+02 7.06576183e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.66161799e-02  1.00134272e+02  6.38033639e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.03143101e-02 1.00194078e+02 7.06576183e-01], Reward: -1, Next state: [-1.09810538e-02  1.00139871e+02  7.10955523e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.03143101e-02 1.00194078e+02 7.06576183e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.09810538e-02  1.00139871e+02  7.10955523e-01], Reward: 0, Next state: [-3.44599088e-03  1.00101074e+02  7.32129622e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.09810538e-02  1.00139871e+02  7.10955523e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-3.44599088e-03  1.00101074e+02  7.32129622e-01], Reward: 0, Next state: [4.17898976e-03 9.99611526e+01 6.58747056e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.44599088e-03  1.00101074e+02  7.32129622e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [4.17898976e-03 9.99611526e+01 6.58747056e-01], Reward: 0, Next state: [-8.00176582e-03  9.99959241e+01  6.13941646e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.17898976e-03 9.99611526e+01 6.58747056e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-8.00176582e-03  9.99959241e+01  6.13941646e-01], Reward: 0, Next state: [2.09479713e-04 9.96323391e+01 3.38132352e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.00176582e-03  9.99959241e+01  6.13941646e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.09479713e-04 9.96323391e+01 3.38132352e-01], Reward: 0, Next state: [1.72353204e-02 9.98329336e+01 6.42211366e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.09479713e-04 9.96323391e+01 3.38132352e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.72353204e-02 9.98329336e+01 6.42211366e-01], Reward: 13.38697585176618, Next state: [-7.89546185e-03  9.99429778e+01  6.45090669e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.72353204e-02 9.98329336e+01 6.42211366e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-7.89546185e-03  9.99429778e+01  6.45090669e-01], Reward: 0, Next state: [-1.42070006e-02  9.96851006e+01  7.93089596e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.89546185e-03  9.99429778e+01  6.45090669e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.42070006e-02  9.96851006e+01  7.93089596e-01], Reward: 0, Next state: [2.18003523e-03 9.96303909e+01 8.30099568e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.42070006e-02  9.96851006e+01  7.93089596e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.18003523e-03 9.96303909e+01 8.30099568e-01], Reward: 0, Next state: [6.47333364e-03 9.96996589e+01 8.11058198e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.18003523e-03 9.96303909e+01 8.30099568e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.47333364e-03 9.96996589e+01 8.11058198e-01], Reward: 196.398566026555, Next state: [1.32845337e-02 9.96914112e+01 7.98131780e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.47333364e-03 9.96996589e+01 8.11058198e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.32845337e-02 9.96914112e+01 7.98131780e-01], Reward: -1, Next state: [-2.05107379e-03  9.98012103e+01  8.90230660e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.32845337e-02 9.96914112e+01 7.98131780e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.05107379e-03  9.98012103e+01  8.90230660e-01], Reward: 0, Next state: [-1.83134759e-02  9.98267214e+01  8.61288736e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.05107379e-03  9.98012103e+01  8.90230660e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.83134759e-02  9.98267214e+01  8.61288736e-01], Reward: 0, Next state: [1.26828596e-02 1.00060001e+02 7.48793473e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.83134759e-02  9.98267214e+01  8.61288736e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.26828596e-02 1.00060001e+02 7.48793473e-01], Reward: 0, Next state: [7.14167716e-03 1.00308176e+02 7.64852109e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.26828596e-02 1.00060001e+02 7.48793473e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [7.14167716e-03 1.00308176e+02 7.64852109e-01], Reward: 0, Next state: [2.61993862e-03 1.00344535e+02 7.97456123e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [7.14167716e-03 1.00308176e+02 7.64852109e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.61993862e-03 1.00344535e+02 7.97456123e-01], Reward: -52.544921837964864, Next state: [-7.80950299e-03  1.00264364e+02  7.74606654e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.61993862e-03 1.00344535e+02 7.97456123e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-7.80950299e-03  1.00264364e+02  7.74606654e-01], Reward: 0, Next state: [1.54143748e-02 1.00862431e+02 6.16359583e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.80950299e-03  1.00264364e+02  7.74606654e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.54143748e-02 1.00862431e+02 6.16359583e-01], Reward: 0, Next state: [-1.51564087e-02  1.00900861e+02  5.74589783e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.54143748e-02 1.00862431e+02 6.16359583e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.51564087e-02  1.00900861e+02  5.74589783e-01], Reward: -1, Next state: [-8.40465980e-03  1.00627610e+02  8.09135547e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.51564087e-02  1.00900861e+02  5.74589783e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-8.40465980e-03  1.00627610e+02  8.09135547e-01], Reward: -1, Next state: [1.84365652e-02 1.00668355e+02 8.37424515e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.40465980e-03  1.00627610e+02  8.09135547e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.84365652e-02 1.00668355e+02 8.37424515e-01], Reward: 0, Next state: [-6.79604408e-03  1.00729318e+02  8.21372890e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.84365652e-02 1.00668355e+02 8.37424515e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-6.79604408e-03  1.00729318e+02  8.21372890e-01], Reward: 116.551408599301, Next state: [1.15818435e-02 1.00714085e+02 8.00432253e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-6.79604408e-03  1.00729318e+02  8.21372890e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.15818435e-02 1.00714085e+02 8.00432253e-01], Reward: 0, Next state: [-3.71868391e-02  1.00250551e+02  1.36226556e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.15818435e-02 1.00714085e+02 8.00432253e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-3.71868391e-02  1.00250551e+02  1.36226556e+00], Reward: 0, Next state: [2.41941945e-02 1.00429934e+02 1.30791155e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.71868391e-02  1.00250551e+02  1.36226556e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.41941945e-02 1.00429934e+02 1.30791155e+00], Reward: 221.53283890731075, Next state: [-1.55415758e-03  1.00211273e+02  1.22963568e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.41941945e-02 1.00429934e+02 1.30791155e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.55415758e-03  1.00211273e+02  1.22963568e+00], Reward: -1, Next state: [2.72953195e-03 1.00185045e+02 1.22173663e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.55415758e-03  1.00211273e+02  1.22963568e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.72953195e-03 1.00185045e+02 1.22173663e+00], Reward: 0, Next state: [-1.40015584e-02  9.96442777e+01  9.57852713e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.72953195e-03 1.00185045e+02 1.22173663e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.40015584e-02  9.96442777e+01  9.57852713e-01], Reward: 0, Next state: [8.29960236e-03 1.00025111e+02 5.04964869e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.40015584e-02  9.96442777e+01  9.57852713e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [8.29960236e-03 1.00025111e+02 5.04964869e-01], Reward: 0, Next state: [7.44825779e-03 1.00080519e+02 5.54127092e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.29960236e-03 1.00025111e+02 5.04964869e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [7.44825779e-03 1.00080519e+02 5.54127092e-01], Reward: 0, Next state: [4.07617970e-03 1.00249191e+02 6.86046364e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [7.44825779e-03 1.00080519e+02 5.54127092e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [4.07617970e-03 1.00249191e+02 6.86046364e-01], Reward: -1, Next state: [-1.23497421e-02  1.00113506e+02  6.89761825e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.07617970e-03 1.00249191e+02 6.86046364e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.23497421e-02  1.00113506e+02  6.89761825e-01], Reward: 73.23845661216097, Next state: [3.63214670e-05 1.00259983e+02 5.12916907e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.23497421e-02  1.00113506e+02  6.89761825e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.63214670e-05 1.00259983e+02 5.12916907e-01], Reward: 0, Next state: [-1.87733605e-03  1.00204489e+02  5.59884289e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.63214670e-05 1.00259983e+02 5.12916907e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.87733605e-03  1.00204489e+02  5.59884289e-01], Reward: 104.81425792094825, Next state: [1.05193462e-02 1.00209783e+02 5.64284763e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.87733605e-03  1.00204489e+02  5.59884289e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.05193462e-02 1.00209783e+02 5.64284763e-01], Reward: -1, Next state: [-6.39483289e-03  1.00004237e+02  3.64918668e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.05193462e-02 1.00209783e+02 5.64284763e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-6.39483289e-03  1.00004237e+02  3.64918668e-01], Reward: 0, Next state: [6.33256064e-03 1.00175039e+02 4.33648261e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-6.39483289e-03  1.00004237e+02  3.64918668e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.33256064e-03 1.00175039e+02 4.33648261e-01], Reward: -222.8979405348383, Next state: [-2.21398381e-02  9.98993207e+01  8.27101092e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.33256064e-03 1.00175039e+02 4.33648261e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.21398381e-02  9.98993207e+01  8.27101092e-01], Reward: -1, Next state: [2.24050066e-02 1.00102231e+02 8.62179273e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.21398381e-02  9.98993207e+01  8.27101092e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.24050066e-02 1.00102231e+02 8.62179273e-01], Reward: 0, Next state: [2.04298125e-03 1.00136640e+02 8.87905698e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.24050066e-02 1.00102231e+02 8.62179273e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.04298125e-03 1.00136640e+02 8.87905698e-01], Reward: 0, Next state: [-2.36399197e-02  9.98229613e+01  1.11364680e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.04298125e-03 1.00136640e+02 8.87905698e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-2.36399197e-02  9.98229613e+01  1.11364680e+00], Reward: 0, Next state: [1.63680389e-02 9.97049461e+01 1.04607201e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.36399197e-02  9.98229613e+01  1.11364680e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.63680389e-02 9.97049461e+01 1.04607201e+00], Reward: 0, Next state: [5.13212410e-03 1.00135459e+02 8.68133600e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.63680389e-02 9.97049461e+01 1.04607201e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [5.13212410e-03 1.00135459e+02 8.68133600e-01], Reward: -250.40859821233568, Next state: [-2.23186856e-02  9.96757686e+01  1.05930008e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [5.13212410e-03 1.00135459e+02 8.68133600e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.23186856e-02  9.96757686e+01  1.05930008e+00], Reward: -1, Next state: [2.40109952e-02 9.96472746e+01 1.02853991e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.23186856e-02  9.96757686e+01  1.05930008e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.40109952e-02 9.96472746e+01 1.02853991e+00], Reward: -1, Next state: [3.06580551e-03 1.00157400e+02 9.50361571e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.40109952e-02 9.96472746e+01 1.02853991e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [3.06580551e-03 1.00157400e+02 9.50361571e-01], Reward: 0, Next state: [-8.39951251e-03  1.00175441e+02  9.49714389e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.06580551e-03 1.00157400e+02 9.50361571e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-8.39951251e-03  1.00175441e+02  9.49714389e-01], Reward: 0, Next state: [-2.45153851e-02  9.95995726e+01  1.31849973e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.39951251e-03  1.00175441e+02  9.49714389e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.45153851e-02  9.95995726e+01  1.31849973e+00], Reward: -1, Next state: [3.85424648e-02 1.00226046e+02 1.32276517e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.45153851e-02  9.95995726e+01  1.31849973e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.85424648e-02 1.00226046e+02 1.32276517e+00], Reward: 0, Next state: [-1.05827680e-02  1.00165392e+02  1.30569449e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.85424648e-02 1.00226046e+02 1.32276517e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.05827680e-02  1.00165392e+02  1.30569449e+00], Reward: 0, Next state: [-2.62851373e-04  1.00037702e+02  1.24509922e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.05827680e-02  1.00165392e+02  1.30569449e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.62851373e-04  1.00037702e+02  1.24509922e+00], Reward: -1, Next state: [-2.44727144e-03  1.00030592e+02  1.24438220e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.62851373e-04  1.00037702e+02  1.24509922e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.44727144e-03  1.00030592e+02  1.24438220e+00], Reward: 283.5274579514248, Next state: [4.14350417e-03 1.00597647e+02 4.64748256e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.44727144e-03  1.00030592e+02  1.24438220e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [4.14350417e-03 1.00597647e+02 4.64748256e-01], Reward: 0, Next state: [-1.05548562e-02  1.00199143e+02  3.76305204e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.14350417e-03 1.00597647e+02 4.64748256e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.05548562e-02  1.00199143e+02  3.76305204e-01], Reward: -1, Next state: [-7.92225699e-03  9.98577986e+01  6.78981790e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.05548562e-02  1.00199143e+02  3.76305204e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-7.92225699e-03  9.98577986e+01  6.78981790e-01], Reward: 0, Next state: [1.14383121e-02 9.97475417e+01 6.26754629e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.92225699e-03  9.98577986e+01  6.78981790e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.14383121e-02 9.97475417e+01 6.26754629e-01], Reward: 0, Next state: [-1.07967088e-02  9.94708393e+01  6.93428662e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.14383121e-02 9.97475417e+01 6.26754629e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.07967088e-02  9.94708393e+01  6.93428662e-01], Reward: 0, Next state: [2.41575059e-02 9.95883004e+01 8.89468958e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.07967088e-02  9.94708393e+01  6.93428662e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.41575059e-02 9.95883004e+01 8.89468958e-01], Reward: -48.70481088543386, Next state: [-1.77459717e-02  9.95590538e+01  8.94430866e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.41575059e-02 9.95883004e+01 8.89468958e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.77459717e-02  9.95590538e+01  8.94430866e-01], Reward: -1, Next state: [-4.18260752e-03  9.96043453e+01  8.55015736e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.77459717e-02  9.95590538e+01  8.94430866e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.18260752e-03  9.96043453e+01  8.55015736e-01], Reward: -1, Next state: [3.28562956e-03 9.94888398e+01 8.54890618e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.18260752e-03  9.96043453e+01  8.55015736e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [3.28562956e-03 9.94888398e+01 8.54890618e-01], Reward: 0, Next state: [-4.41506442e-03  9.95012682e+01  8.44570257e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.28562956e-03 9.94888398e+01 8.54890618e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-4.41506442e-03  9.95012682e+01  8.44570257e-01], Reward: 0, Next state: [-8.46526701e-03  9.88692369e+01  4.84217189e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.41506442e-03  9.95012682e+01  8.44570257e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-8.46526701e-03  9.88692369e+01  4.84217189e-01], Reward: -1, Next state: [2.47745106e-02 9.90816869e+01 7.86738257e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.46526701e-03  9.88692369e+01  4.84217189e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.47745106e-02 9.90816869e+01 7.86738257e-01], Reward: -1, Next state: [-1.14531639e-02  9.91472388e+01  7.85329897e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.47745106e-02 9.90816869e+01 7.86738257e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.14531639e-02  9.91472388e+01  7.85329897e-01], Reward: -1, Next state: [1.04858167e-02 9.93559463e+01 9.15164904e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.14531639e-02  9.91472388e+01  7.85329897e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.04858167e-02 9.93559463e+01 9.15164904e-01], Reward: -1, Next state: [3.97634907e-03 9.97320679e+01 1.00031332e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.04858167e-02 9.93559463e+01 9.15164904e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.97634907e-03 9.97320679e+01 1.00031332e+00], Reward: 0, Next state: [2.34968838e-05 1.00275971e+02 5.31382383e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.97634907e-03 9.97320679e+01 1.00031332e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.34968838e-05 1.00275971e+02 5.31382383e-01], Reward: -1, Next state: [-4.48658394e-03  1.00244011e+02  5.27058829e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.34968838e-05 1.00275971e+02 5.31382383e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-4.48658394e-03  1.00244011e+02  5.27058829e-01], Reward: 128.0124392772592, Next state: [1.72759106e-02 1.00788444e+02 6.27334615e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.48658394e-03  1.00244011e+02  5.27058829e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.72759106e-02 1.00788444e+02 6.27334615e-01], Reward: 0, Next state: [-1.90985695e-02  1.00735161e+02  6.75804613e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.72759106e-02 1.00788444e+02 6.27334615e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.90985695e-02  1.00735161e+02  6.75804613e-01], Reward: -1, Next state: [1.26992125e-02 1.00856186e+02 7.12083539e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.90985695e-02  1.00735161e+02  6.75804613e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.26992125e-02 1.00856186e+02 7.12083539e-01], Reward: -1, Next state: [-2.50538445e-02  1.00469116e+02  1.10659856e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.26992125e-02 1.00856186e+02 7.12083539e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-2.50538445e-02  1.00469116e+02  1.10659856e+00], Reward: 0, Next state: [2.56210538e-02 1.00678517e+02 1.14406900e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.50538445e-02  1.00469116e+02  1.10659856e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.56210538e-02 1.00678517e+02 1.14406900e+00], Reward: 0, Next state: [-3.29946752e-02  9.98730675e+01  1.34220049e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.56210538e-02 1.00678517e+02 1.14406900e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-3.29946752e-02  9.98730675e+01  1.34220049e+00], Reward: -159.97046016956915, Next state: [1.77896822e-02 9.98056885e+01 1.34079147e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.29946752e-02  9.98730675e+01  1.34220049e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.77896822e-02 9.98056885e+01 1.34079147e+00], Reward: 0, Next state: [1.41595239e-03 9.95124680e+01 1.12322784e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.77896822e-02 9.98056885e+01 1.34079147e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.41595239e-03 9.95124680e+01 1.12322784e+00], Reward: 0, Next state: [-1.26080130e-02  9.94751124e+01  1.15014422e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.41595239e-03 9.95124680e+01 1.12322784e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.26080130e-02  9.94751124e+01  1.15014422e+00], Reward: -1, Next state: [6.18315864e-03 9.90535570e+01 7.04408308e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.26080130e-02  9.94751124e+01  1.15014422e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.18315864e-03 9.90535570e+01 7.04408308e-01], Reward: 0, Next state: [1.07250790e-02 9.95132311e+01 5.76798163e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.18315864e-03 9.90535570e+01 7.04408308e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.07250790e-02 9.95132311e+01 5.76798163e-01], Reward: 0, Next state: [7.39315874e-03 9.97726224e+01 8.35581775e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.07250790e-02 9.95132311e+01 5.76798163e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [7.39315874e-03 9.97726224e+01 8.35581775e-01], Reward: -1, Next state: [-1.43355722e-02  9.97142131e+01  8.39020093e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [7.39315874e-03 9.97726224e+01 8.35581775e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.43355722e-02  9.97142131e+01  8.39020093e-01], Reward: 0, Next state: [-2.59229817e-03  9.98559492e+01  6.80573785e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.43355722e-02  9.97142131e+01  8.39020093e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.59229817e-03  9.98559492e+01  6.80573785e-01], Reward: -10.070782852226046, Next state: [-1.01427919e-03  9.98556350e+01  6.80881077e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.59229817e-03  9.98559492e+01  6.80573785e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.01427919e-03  9.98556350e+01  6.80881077e-01], Reward: 0, Next state: [1.83597666e-02 1.00006773e+02 8.21955411e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.01427919e-03  9.98556350e+01  6.80881077e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.83597666e-02 1.00006773e+02 8.21955411e-01], Reward: 0, Next state: [-2.31977387e-02  9.95410291e+01  7.88596007e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.83597666e-02 1.00006773e+02 8.21955411e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.31977387e-02  9.95410291e+01  7.88596007e-01], Reward: 0, Next state: [-1.00784762e-02  9.91659687e+01  1.08593569e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.31977387e-02  9.95410291e+01  7.88596007e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.00784762e-02  9.91659687e+01  1.08593569e+00], Reward: -1, Next state: [1.09684785e-02 9.90567844e+01 1.09537493e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.00784762e-02  9.91659687e+01  1.08593569e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.09684785e-02 9.90567844e+01 1.09537493e+00], Reward: 0, Next state: [3.40458586e-03 9.90349782e+01 1.09360286e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.09684785e-02 9.90567844e+01 1.09537493e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [3.40458586e-03 9.90349782e+01 1.09360286e+00], Reward: 0, Next state: [1.34670944e-03 9.86756399e+01 5.41063990e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.40458586e-03 9.90349782e+01 1.09360286e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.34670944e-03 9.86756399e+01 5.41063990e-01], Reward: -1, Next state: [1.00357432e-02 9.89840810e+01 8.17373490e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.34670944e-03 9.86756399e+01 5.41063990e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.00357432e-02 9.89840810e+01 8.17373490e-01], Reward: 0, Next state: [-1.85372914e-03  9.94542530e+01  5.65061700e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.00357432e-02 9.89840810e+01 8.17373490e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.85372914e-03  9.94542530e+01  5.65061700e-01], Reward: 0, Next state: [1.81197729e-02 1.00072642e+02 9.85212833e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.85372914e-03  9.94542530e+01  5.65061700e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.81197729e-02 1.00072642e+02 9.85212833e-01], Reward: 0, Next state: [-2.84062481e-02  1.00045238e+02  1.01392105e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.81197729e-02 1.00072642e+02 9.85212833e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-2.84062481e-02  1.00045238e+02  1.01392105e+00], Reward: 0, Next state: [7.53845394e-03 1.00140323e+02 9.51879410e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.84062481e-02  1.00045238e+02  1.01392105e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [7.53845394e-03 1.00140323e+02 9.51879410e-01], Reward: 23.155088292220682, Next state: [2.32272860e-03 1.00082582e+02 9.54688711e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [7.53845394e-03 1.00140323e+02 9.51879410e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.32272860e-03 1.00082582e+02 9.54688711e-01], Reward: -1, Next state: [-1.59861284e-02  9.97425242e+01  1.18914234e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.32272860e-03 1.00082582e+02 9.54688711e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.59861284e-02  9.97425242e+01  1.18914234e+00], Reward: -1, Next state: [2.13904489e-02 9.94606213e+01 7.42686512e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.59861284e-02  9.97425242e+01  1.18914234e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.13904489e-02 9.94606213e+01 7.42686512e-01], Reward: 0, Next state: [5.03415647e-04 9.97673858e+01 7.81410756e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.13904489e-02 9.94606213e+01 7.42686512e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [5.03415647e-04 9.97673858e+01 7.81410756e-01], Reward: 0, Next state: [-4.92204436e-03  9.98260638e+01  7.84344281e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [5.03415647e-04 9.97673858e+01 7.81410756e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.92204436e-03  9.98260638e+01  7.84344281e-01], Reward: -1, Next state: [-6.15745453e-03  9.97153040e+01  8.02059082e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.92204436e-03  9.98260638e+01  7.84344281e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-6.15745453e-03  9.97153040e+01  8.02059082e-01], Reward: 0, Next state: [-2.21664779e-04  9.99196081e+01  4.91432058e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-6.15745453e-03  9.97153040e+01  8.02059082e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-2.21664779e-04  9.99196081e+01  4.91432058e-01], Reward: 0, Next state: [1.47577123e-02 9.99964966e+01 5.85755657e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.21664779e-04  9.99196081e+01  4.91432058e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.47577123e-02 9.99964966e+01 5.85755657e-01], Reward: 0, Next state: [-2.33721439e-02  9.95920400e+01  7.80175910e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.47577123e-02 9.99964966e+01 5.85755657e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.33721439e-02  9.95920400e+01  7.80175910e-01], Reward: 21.534849785696508, Next state: [2.27274915e-02 9.97340203e+01 8.94538929e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.33721439e-02  9.95920400e+01  7.80175910e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.27274915e-02 9.97340203e+01 8.94538929e-01], Reward: 0, Next state: [-2.78864938e-02  9.94375362e+01  1.17025190e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.27274915e-02 9.97340203e+01 8.94538929e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.78864938e-02  9.94375362e+01  1.17025190e+00], Reward: -1, Next state: [2.09247801e-02 9.95550997e+01 1.18447948e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.78864938e-02  9.94375362e+01  1.17025190e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.09247801e-02 9.95550997e+01 1.18447948e+00], Reward: -1, Next state: [-2.57530406e-03  9.93279711e+01  1.01923524e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.09247801e-02 9.95550997e+01 1.18447948e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.57530406e-03  9.93279711e+01  1.01923524e+00], Reward: -1, Next state: [4.14188257e-02 1.00397764e+02 1.93610476e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.57530406e-03  9.93279711e+01  1.01923524e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [4.14188257e-02 1.00397764e+02 1.93610476e+00], Reward: 0, Next state: [-4.14058708e-02  1.00160413e+02  1.95804770e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.14188257e-02 1.00397764e+02 1.93610476e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-4.14058708e-02  1.00160413e+02  1.95804770e+00], Reward: 64.4859701905105, Next state: [6.48063048e-03 1.00613625e+02 1.61015932e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.14058708e-02  1.00160413e+02  1.95804770e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [6.48063048e-03 1.00613625e+02 1.61015932e+00], Reward: 0, Next state: [-5.03448513e-05  1.00656187e+02  1.59433278e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.48063048e-03 1.00613625e+02 1.61015932e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-5.03448513e-05  1.00656187e+02  1.59433278e+00], Reward: -121.46632978919456, Next state: [-1.21289826e-02  1.00507288e+02  1.70958217e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-5.03448513e-05  1.00656187e+02  1.59433278e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.21289826e-02  1.00507288e+02  1.70958217e+00], Reward: 0, Next state: [3.72445942e-04 9.95400711e+01 5.36506498e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.21289826e-02  1.00507288e+02  1.70958217e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.72445942e-04 9.95400711e+01 5.36506498e-01], Reward: 0, Next state: [1.23760736e-02 9.96774376e+01 5.94874612e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.72445942e-04 9.95400711e+01 5.36506498e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.23760736e-02 9.96774376e+01 5.94874612e-01], Reward: 0, Next state: [1.72104829e-02 1.00030704e+02 1.08965404e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.23760736e-02 9.96774376e+01 5.94874612e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.72104829e-02 1.00030704e+02 1.08965404e+00], Reward: 0, Next state: [-3.11815609e-02  9.97493942e+01  1.19970369e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.72104829e-02 1.00030704e+02 1.08965404e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.11815609e-02  9.97493942e+01  1.19970369e+00], Reward: -1, Next state: [1.43703738e-02 9.99947998e+01 1.13068046e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.11815609e-02  9.97493942e+01  1.19970369e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.43703738e-02 9.99947998e+01 1.13068046e+00], Reward: -77.91203067828576, Next state: [-7.43296621e-03  1.00083942e+02  1.06165373e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.43703738e-02 9.99947998e+01 1.13068046e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-7.43296621e-03  1.00083942e+02  1.06165373e+00], Reward: -1, Next state: [3.86908842e-03 1.00005046e+02 1.06530354e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.43296621e-03  1.00083942e+02  1.06165373e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [3.86908842e-03 1.00005046e+02 1.06530354e+00], Reward: -1, Next state: [1.71919835e-02 9.99244226e+01 9.23359269e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.86908842e-03 1.00005046e+02 1.06530354e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.71919835e-02 9.99244226e+01 9.23359269e-01], Reward: 0, Next state: [-3.06227827e-02  9.98576580e+01  1.01425577e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.71919835e-02 9.99244226e+01 9.23359269e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.06227827e-02  9.98576580e+01  1.01425577e+00], Reward: -1, Next state: [4.02205978e-02 1.00298693e+02 1.43930022e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.06227827e-02  9.98576580e+01  1.01425577e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [4.02205978e-02 1.00298693e+02 1.43930022e+00], Reward: 0, Next state: [-1.47231790e-02  1.00587200e+02  1.37612264e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.02205978e-02 1.00298693e+02 1.43930022e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.47231790e-02  1.00587200e+02  1.37612264e+00], Reward: 0, Next state: [-7.69262349e-03  1.00643610e+02  1.34811378e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.47231790e-02  1.00587200e+02  1.37612264e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-7.69262349e-03  1.00643610e+02  1.34811378e+00], Reward: -1, Next state: [-5.38161404e-03  1.00249156e+02  1.32412252e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.69262349e-03  1.00643610e+02  1.34811378e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-5.38161404e-03  1.00249156e+02  1.32412252e+00], Reward: 0, Next state: [6.28698407e-03 1.00601592e+02 9.74861632e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-5.38161404e-03  1.00249156e+02  1.32412252e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.28698407e-03 1.00601592e+02 9.74861632e-01], Reward: -86.09631172770236, Next state: [-9.46602585e-03  9.99728082e+01  5.62729482e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.28698407e-03 1.00601592e+02 9.74861632e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-9.46602585e-03  9.99728082e+01  5.62729482e-01], Reward: -1, Next state: [-2.35992101e-03  9.95986164e+01  4.64555835e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-9.46602585e-03  9.99728082e+01  5.62729482e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.35992101e-03  9.95986164e+01  4.64555835e-01], Reward: -1, Next state: [2.16239488e-02 9.98076832e+01 7.69398798e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.35992101e-03  9.95986164e+01  4.64555835e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.16239488e-02 9.98076832e+01 7.69398798e-01], Reward: 0, Next state: [-4.38464564e-04  1.00115600e+02  8.98504237e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.16239488e-02 9.98076832e+01 7.69398798e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.38464564e-04  1.00115600e+02  8.98504237e-01], Reward: -1, Next state: [-9.05894984e-03  1.00115217e+02  8.98482480e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.38464564e-04  1.00115600e+02  8.98504237e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-9.05894984e-03  1.00115217e+02  8.98482480e-01], Reward: -118.4280557530812, Next state: [-2.68148402e-03  1.00250752e+02  7.98655445e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-9.05894984e-03  1.00115217e+02  8.98482480e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.68148402e-03  1.00250752e+02  7.98655445e-01], Reward: -1, Next state: [4.17062023e-03 1.00516444e+02 4.97609690e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.68148402e-03  1.00250752e+02  7.98655445e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [4.17062023e-03 1.00516444e+02 4.97609690e-01], Reward: -1, Next state: [-4.90507468e-03  1.00255637e+02  4.49483871e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.17062023e-03 1.00516444e+02 4.97609690e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-4.90507468e-03  1.00255637e+02  4.49483871e-01], Reward: 0, Next state: [-1.61596800e-02  9.96810818e+01  7.57590224e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.90507468e-03  1.00255637e+02  4.49483871e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.61596800e-02  9.96810818e+01  7.57590224e-01], Reward: -1, Next state: [8.25331101e-03 9.94517731e+01 7.49767411e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.61596800e-02  9.96810818e+01  7.57590224e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [8.25331101e-03 9.94517731e+01 7.49767411e-01], Reward: 256.8037314812173, Next state: [1.77490768e-02 9.96276816e+01 9.17878423e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.25331101e-03 9.94517731e+01 7.49767411e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.77490768e-02 9.96276816e+01 9.17878423e-01], Reward: -1, Next state: [6.92165884e-04 9.97342144e+01 1.01686364e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.77490768e-02 9.96276816e+01 9.17878423e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [6.92165884e-04 9.97342144e+01 1.01686364e+00], Reward: -1, Next state: [-1.28920545e-02  9.96791336e+01  1.01810714e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.92165884e-04 9.97342144e+01 1.01686364e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.28920545e-02  9.96791336e+01  1.01810714e+00], Reward: 0, Next state: [2.03627420e-02 1.00352075e+02 9.31882425e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.28920545e-02  9.96791336e+01  1.01810714e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.03627420e-02 1.00352075e+02 9.31882425e-01], Reward: 0, Next state: [-3.15643262e-03  1.00798786e+02  6.89558333e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.03627420e-02 1.00352075e+02 9.31882425e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.15643262e-03  1.00798786e+02  6.89558333e-01], Reward: -1, Next state: [-1.78540188e-02  1.00532446e+02  8.78171176e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.15643262e-03  1.00798786e+02  6.89558333e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.78540188e-02  1.00532446e+02  8.78171176e-01], Reward: 0, Next state: [1.72559189e-03 1.00286475e+02 9.26760140e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.78540188e-02  1.00532446e+02  8.78171176e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.72559189e-03 1.00286475e+02 9.26760140e-01], Reward: -51.25201671915107, Next state: [-5.14494485e-03  1.00198023e+02  1.01053080e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.72559189e-03 1.00286475e+02 9.26760140e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-5.14494485e-03  1.00198023e+02  1.01053080e+00], Reward: -1, Next state: [9.83513012e-03 9.98991043e+01 7.46023415e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-5.14494485e-03  1.00198023e+02  1.01053080e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [9.83513012e-03 9.98991043e+01 7.46023415e-01], Reward: 0, Next state: [-1.14875365e-02  9.94343766e+01  4.03223924e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.83513012e-03 9.98991043e+01 7.46023415e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.14875365e-02  9.94343766e+01  4.03223924e-01], Reward: 0, Next state: [1.10890872e-02 9.95506074e+01 4.67993978e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.14875365e-02  9.94343766e+01  4.03223924e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.10890872e-02 9.95506074e+01 4.67993978e-01], Reward: 186.2879891591419, Next state: [7.65652339e-03 9.97856881e+01 6.86248897e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.10890872e-02 9.95506074e+01 4.67993978e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [7.65652339e-03 9.97856881e+01 6.86248897e-01], Reward: 0, Next state: [-1.25468398e-02  9.98703494e+01  6.19789107e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [7.65652339e-03 9.97856881e+01 6.86248897e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.25468398e-02  9.98703494e+01  6.19789107e-01], Reward: 0, Next state: [2.42756373e-03 9.98083927e+01 6.11316633e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.25468398e-02  9.98703494e+01  6.19789107e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.42756373e-03 9.98083927e+01 6.11316633e-01], Reward: 64.58383193536008, Next state: [4.05167404e-03 1.00057213e+02 4.28515022e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.42756373e-03 9.98083927e+01 6.11316633e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [4.05167404e-03 1.00057213e+02 4.28515022e-01], Reward: 0, Next state: [-3.33655659e-03  1.00019781e+02  4.37699084e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [4.05167404e-03 1.00057213e+02 4.28515022e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-3.33655659e-03  1.00019781e+02  4.37699084e-01], Reward: 105.95905341070448, Next state: [1.06130292e-02 1.00041097e+02 4.75714954e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.33655659e-03  1.00019781e+02  4.37699084e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.06130292e-02 1.00041097e+02 4.75714954e-01], Reward: 0, Next state: [-1.41633402e-02  1.00029525e+02  4.88607699e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.06130292e-02 1.00041097e+02 4.75714954e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.41633402e-02  1.00029525e+02  4.88607699e-01], Reward: 0, Next state: [7.05783978e-03 1.00110039e+02 4.71868826e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.41633402e-02  1.00029525e+02  4.88607699e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [7.05783978e-03 1.00110039e+02 4.71868826e-01], Reward: 0, Next state: [8.82891266e-03 1.00286587e+02 6.07888660e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [7.05783978e-03 1.00110039e+02 4.71868826e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [8.82891266e-03 1.00286587e+02 6.07888660e-01], Reward: 0, Next state: [-9.69186615e-03  1.00334099e+02  5.79649844e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.82891266e-03 1.00286587e+02 6.07888660e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-9.69186615e-03  1.00334099e+02  5.79649844e-01], Reward: -43.19458279534274, Next state: [-3.36674624e-03  1.00102306e+02  5.37937033e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-9.69186615e-03  1.00334099e+02  5.79649844e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-3.36674624e-03  1.00102306e+02  5.37937033e-01], Reward: 0, Next state: [1.14996473e-02 1.00385717e+02 5.01795327e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.36674624e-03  1.00102306e+02  5.37937033e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.14996473e-02 1.00385717e+02 5.01795327e-01], Reward: -1, Next state: [2.57832679e-02 1.01048957e+02 1.31408728e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.14996473e-02 1.00385717e+02 5.01795327e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.57832679e-02 1.01048957e+02 1.31408728e+00], Reward: -81.49094687970688, Next state: [-3.30096787e-02  1.00852099e+02  1.37084347e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.57832679e-02 1.01048957e+02 1.31408728e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-3.30096787e-02  1.00852099e+02  1.37084347e+00], Reward: 0, Next state: [2.54523429e-02 1.01360534e+02 1.45748383e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.30096787e-02  1.00852099e+02  1.37084347e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.54523429e-02 1.01360534e+02 1.45748383e+00], Reward: -289.11148393580106, Next state: [-2.81734585e-02  1.01358132e+02  1.46016070e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.54523429e-02 1.01360534e+02 1.45748383e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.81734585e-02  1.01358132e+02  1.46016070e+00], Reward: 0, Next state: [1.53974230e-02 1.01433446e+02 1.44349535e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.81734585e-02  1.01358132e+02  1.46016070e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.53974230e-02 1.01433446e+02 1.44349535e+00], Reward: 0, Next state: [-3.68501331e-03  1.00913893e+02  1.01445584e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.53974230e-02 1.01433446e+02 1.44349535e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-3.68501331e-03  1.00913893e+02  1.01445584e+00], Reward: 0, Next state: [-5.52851074e-03  1.00966004e+02  9.75792085e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.68501331e-03  1.00913893e+02  1.01445584e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-5.52851074e-03  1.00966004e+02  9.75792085e-01], Reward: -1, Next state: [-1.10084641e-02  1.00287805e+02  7.42090774e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-5.52851074e-03  1.00966004e+02  9.75792085e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.10084641e-02  1.00287805e+02  7.42090774e-01], Reward: 0, Next state: [2.53595629e-02 1.00691101e+02 8.65545014e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.10084641e-02  1.00287805e+02  7.42090774e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.53595629e-02 1.00691101e+02 8.65545014e-01], Reward: 0, Next state: [-8.56115288e-03  1.00613080e+02  8.27227930e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.53595629e-02 1.00691101e+02 8.65545014e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-8.56115288e-03  1.00613080e+02  8.27227930e-01], Reward: -164.566472882278, Next state: [-1.63142712e-02  1.00280557e+02  9.70903878e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.56115288e-03  1.00613080e+02  8.27227930e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.63142712e-02  1.00280557e+02  9.70903878e-01], Reward: 0, Next state: [3.10850325e-03 1.00121278e+02 1.01379573e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.63142712e-02  1.00280557e+02  9.70903878e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [3.10850325e-03 1.00121278e+02 1.01379573e+00], Reward: -1, Next state: [1.53521955e-02 1.00488516e+02 9.54304826e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.10850325e-03 1.00121278e+02 1.01379573e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.53521955e-02 1.00488516e+02 9.54304826e-01], Reward: 0, Next state: [-1.12501419e-02  1.00125085e+02  7.25700787e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.53521955e-02 1.00488516e+02 9.54304826e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.12501419e-02  1.00125085e+02  7.25700787e-01], Reward: 0, Next state: [1.32037934e-03 9.99622517e+01 6.23878374e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.12501419e-02  1.00125085e+02  7.25700787e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.32037934e-03 9.99622517e+01 6.23878374e-01], Reward: 0, Next state: [-7.34128551e-03  9.99816395e+01  6.01846876e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.32037934e-03 9.99622517e+01 6.23878374e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-7.34128551e-03  9.99816395e+01  6.01846876e-01], Reward: -1, Next state: [-1.08105536e-02  9.97245884e+01  9.25141294e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.34128551e-03  9.99816395e+01  6.01846876e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.08105536e-02  9.97245884e+01  9.25141294e-01], Reward: -1, Next state: [1.80158003e-02 9.95159309e+01 6.86481484e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.08105536e-02  9.97245884e+01  9.25141294e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.80158003e-02 9.95159309e+01 6.86481484e-01], Reward: 0, Next state: [-1.19276946e-02  9.92960670e+01  6.95725841e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.80158003e-02 9.95159309e+01 6.86481484e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.19276946e-02  9.92960670e+01  6.95725841e-01], Reward: 0, Next state: [1.16016735e-02 9.92791273e+01 6.77753679e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.19276946e-02  9.92960670e+01  6.95725841e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.16016735e-02 9.92791273e+01 6.77753679e-01], Reward: -1, Next state: [6.97320347e-03 9.95485268e+01 8.79672033e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.16016735e-02 9.92791273e+01 6.77753679e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.97320347e-03 9.95485268e+01 8.79672033e-01], Reward: -59.91904950818707, Next state: [-1.20355423e-02  9.97903498e+01  6.16297989e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.97320347e-03 9.95485268e+01 8.79672033e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.20355423e-02  9.97903498e+01  6.16297989e-01], Reward: 0, Next state: [1.58266477e-03 9.97096437e+01 6.07257385e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.20355423e-02  9.97903498e+01  6.16297989e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.58266477e-03 9.97096437e+01 6.07257385e-01], Reward: 0, Next state: [-7.17283995e-03  9.97246328e+01  5.85840019e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.58266477e-03 9.97096437e+01 6.07257385e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-7.17283995e-03  9.97246328e+01  5.85840019e-01], Reward: 10.559452550523929, Next state: [8.29232710e-03 9.96743355e+01 5.72938562e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.17283995e-03  9.97246328e+01  5.85840019e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [8.29232710e-03 9.96743355e+01 5.72938562e-01], Reward: 0, Next state: [2.43196577e-03 9.95331148e+01 3.55721589e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.29232710e-03 9.96743355e+01 5.72938562e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.43196577e-03 9.95331148e+01 3.55721589e-01], Reward: 109.24704041282922, Next state: [1.09285424e-02 9.98527143e+01 6.98543718e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.43196577e-03 9.95331148e+01 3.55721589e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.09285424e-02 9.98527143e+01 6.98543718e-01], Reward: 0, Next state: [-1.65286357e-02  9.98067635e+01  7.19787186e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.09285424e-02 9.98527143e+01 6.98543718e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.65286357e-02  9.98067635e+01  7.19787186e-01], Reward: 3.0142745593593645, Next state: [3.03286578e-04 9.99097483e+01 6.11727074e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.65286357e-02  9.98067635e+01  7.19787186e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.03286578e-04 9.99097483e+01 6.11727074e-01], Reward: 0, Next state: [1.51684377e-02 1.00150308e+02 7.18002549e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.03286578e-04 9.99097483e+01 6.11727074e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.51684377e-02 1.00150308e+02 7.18002549e-01], Reward: -1, Next state: [-1.61860028e-02  1.00015648e+02  7.98749395e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.51684377e-02 1.00150308e+02 7.18002549e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-1.61860028e-02  1.00015648e+02  7.98749395e-01], Reward: -55.147919540884516, Next state: [1.08981611e-02 9.98789132e+01 6.54150541e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.61860028e-02  1.00015648e+02  7.98749395e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.08981611e-02 9.98789132e+01 6.54150541e-01], Reward: -1, Next state: [-3.18706253e-03  1.00012267e+02  6.06507252e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.08981611e-02 9.98789132e+01 6.54150541e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-3.18706253e-03  1.00012267e+02  6.06507252e-01], Reward: 0, Next state: [-2.30240021e-03  1.00093520e+02  5.45481022e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.18706253e-03  1.00012267e+02  6.06507252e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-2.30240021e-03  1.00093520e+02  5.45481022e-01], Reward: 0, Next state: [1.00873006e-02 1.00074561e+02 5.17160029e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.30240021e-03  1.00093520e+02  5.45481022e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.00873006e-02 1.00074561e+02 5.17160029e-01], Reward: -1, Next state: [-2.51681258e-02  9.98747758e+01  8.60214374e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.00873006e-02 1.00074561e+02 5.17160029e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.51681258e-02  9.98747758e+01  8.60214374e-01], Reward: -6.582443054973908, Next state: [1.49038409e-02 9.97515587e+01 8.23257470e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.51681258e-02  9.98747758e+01  8.60214374e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.49038409e-02 9.97515587e+01 8.23257470e-01], Reward: 0, Next state: [-6.01978199e-03  9.95722172e+01  8.35467295e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.49038409e-02 9.97515587e+01 8.23257470e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-6.01978199e-03  9.95722172e+01  8.35467295e-01], Reward: -1, Next state: [1.86118802e-02 9.98080485e+01 1.01928943e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-6.01978199e-03  9.95722172e+01  8.35467295e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.86118802e-02 9.98080485e+01 1.01928943e+00], Reward: 0, Next state: [-1.91898184e-02  9.94548457e+01  9.03211782e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.86118802e-02 9.98080485e+01 1.01928943e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.91898184e-02  9.94548457e+01  9.03211782e-01], Reward: -1, Next state: [1.26423925e-02 9.98596673e+01 7.28251757e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.91898184e-02  9.94548457e+01  9.03211782e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.26423925e-02 9.98596673e+01 7.28251757e-01], Reward: 112.25106653397319, Next state: [-3.70608627e-04  9.99640657e+01  7.43392952e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.26423925e-02 9.98596673e+01 7.28251757e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-3.70608627e-04  9.99640657e+01  7.43392952e-01], Reward: 0, Next state: [-1.52482017e-02  9.98827512e+01  8.42806144e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.70608627e-04  9.99640657e+01  7.43392952e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.52482017e-02  9.98827512e+01  8.42806144e-01], Reward: 0, Next state: [2.81744097e-02 9.99887841e+01 9.96378204e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.52482017e-02  9.98827512e+01  8.42806144e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [2.81744097e-02 9.99887841e+01 9.96378204e-01], Reward: 0, Next state: [-1.65567332e-02  1.00146251e+02  8.94883651e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.81744097e-02 9.99887841e+01 9.96378204e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.65567332e-02  1.00146251e+02  8.94883651e-01], Reward: 0, Next state: [1.16136214e-02 1.00285164e+02 9.61964379e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.65567332e-02  1.00146251e+02  8.94883651e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.16136214e-02 1.00285164e+02 9.61964379e-01], Reward: 214.4250169708002, Next state: [-1.15408909e-03  1.00408198e+02  9.92245152e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.16136214e-02 1.00285164e+02 9.61964379e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.15408909e-03  1.00408198e+02  9.92245152e-01], Reward: 0, Next state: [-4.87194913e-03  1.00738737e+02  5.70706072e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.15408909e-03  1.00408198e+02  9.92245152e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-4.87194913e-03  1.00738737e+02  5.70706072e-01], Reward: -1, Next state: [-1.98921023e-04  1.00508834e+02  4.14779402e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-4.87194913e-03  1.00738737e+02  5.70706072e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.98921023e-04  1.00508834e+02  4.14779402e-01], Reward: 0, Next state: [-7.89026061e-03  1.00456732e+02  5.01377078e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.98921023e-04  1.00508834e+02  4.14779402e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-7.89026061e-03  1.00456732e+02  5.01377078e-01], Reward: 0, Next state: [-1.96566913e-03  1.00133549e+02  5.57403450e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.89026061e-03  1.00456732e+02  5.01377078e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-1.96566913e-03  1.00133549e+02  5.57403450e-01], Reward: -1, Next state: [8.72865884e-03 1.00007198e+02 4.26849819e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.96566913e-03  1.00133549e+02  5.57403450e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [8.72865884e-03 1.00007198e+02 4.26849819e-01], Reward: 0, Next state: [3.16106986e-03 1.00042547e+02 4.63890412e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.72865884e-03 1.00007198e+02 4.26849819e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [3.16106986e-03 1.00042547e+02 4.63890412e-01], Reward: -151.34673649778279, Next state: [-1.68046334e-02  9.97438476e+01  6.07091697e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.16106986e-03 1.00042547e+02 4.63890412e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.68046334e-02  9.97438476e+01  6.07091697e-01], Reward: 0, Next state: [5.23701820e-03 9.97071360e+01 6.20613616e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.68046334e-02  9.97438476e+01  6.07091697e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [5.23701820e-03 9.97071360e+01 6.20613616e-01], Reward: -75.37724339949392, Next state: [-7.58264289e-03  9.95588226e+01  7.52074183e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [5.23701820e-03 9.97071360e+01 6.20613616e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-7.58264289e-03  9.95588226e+01  7.52074183e-01], Reward: -1, Next state: [1.50487520e-02 9.95339149e+01 7.30081103e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-7.58264289e-03  9.95588226e+01  7.52074183e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.50487520e-02 9.95339149e+01 7.30081103e-01], Reward: 0, Next state: [1.02078327e-02 9.96500589e+01 9.11018081e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.50487520e-02 9.95339149e+01 7.30081103e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.02078327e-02 9.96500589e+01 9.11018081e-01], Reward: -1, Next state: [9.98252919e-04 1.00124441e+02 1.00435655e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.02078327e-02 9.96500589e+01 9.11018081e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [9.98252919e-04 1.00124441e+02 1.00435655e+00], Reward: -275.5217816326848, Next state: [-2.82061575e-02  9.99240061e+01  1.20697327e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.98252919e-04 1.00124441e+02 1.00435655e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.82061575e-02  9.99240061e+01  1.20697327e+00], Reward: -1, Next state: [2.62082980e-02 1.00390133e+02 1.06853434e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.82061575e-02  9.99240061e+01  1.20697327e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.62082980e-02 1.00390133e+02 1.06853434e+00], Reward: 0, Next state: [-2.13177761e-02  1.00128784e+02  1.24359542e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.62082980e-02 1.00390133e+02 1.06853434e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-2.13177761e-02  1.00128784e+02  1.24359542e+00], Reward: -1, Next state: [1.54906535e-02 9.99691887e+01 1.14849849e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.13177761e-02  1.00128784e+02  1.24359542e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.54906535e-02 9.99691887e+01 1.14849849e+00], Reward: 0, Next state: [1.66076376e-03 9.98227326e+01 1.01305077e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.54906535e-02 9.99691887e+01 1.14849849e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [1.66076376e-03 9.98227326e+01 1.01305077e+00], Reward: -1, Next state: [-8.78989643e-03  1.00070788e+02  7.54494529e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.66076376e-03 9.98227326e+01 1.01305077e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-8.78989643e-03  1.00070788e+02  7.54494529e-01], Reward: 0, Next state: [-1.28205754e-03  9.97774858e+01  6.14323592e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-8.78989643e-03  1.00070788e+02  7.54494529e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.28205754e-03  9.97774858e+01  6.14323592e-01], Reward: 0, Next state: [1.25436178e-03 9.99397026e+01 4.19296746e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.28205754e-03  9.97774858e+01  6.14323592e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.25436178e-03 9.99397026e+01 4.19296746e-01], Reward: -33.79548272928332, Next state: [-3.39166345e-03  9.97281348e+01  4.19376752e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.25436178e-03 9.99397026e+01 4.19296746e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-3.39166345e-03  9.97281348e+01  4.19376752e-01], Reward: 0, Next state: [1.19330552e-02 9.97202334e+01 4.04307942e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.39166345e-03  9.97281348e+01  4.19376752e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.19330552e-02 9.97202334e+01 4.04307942e-01], Reward: 0, Next state: [1.45648156e-02 1.00181784e+02 9.73032471e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.19330552e-02 9.97202334e+01 4.04307942e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.45648156e-02 1.00181784e+02 9.73032471e-01], Reward: -343.945442721531, Next state: [-3.37355318e-02  9.99809934e+01  1.17244881e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.45648156e-02 1.00181784e+02 9.73032471e-01]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-3.37355318e-02  9.99809934e+01  1.17244881e+00], Reward: -1, Next state: [6.54697415e-03 9.98842305e+01 1.21554036e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.37355318e-02  9.99809934e+01  1.17244881e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [6.54697415e-03 9.98842305e+01 1.21554036e+00], Reward: 0, Next state: [1.45559729e-02 1.00143730e+02 1.20257862e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.54697415e-03 9.98842305e+01 1.21554036e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [1.45559729e-02 1.00143730e+02 1.20257862e+00], Reward: 0, Next state: [-9.65255505e-03  9.99720130e+01  1.20219479e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.45559729e-02 1.00143730e+02 1.20257862e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [-9.65255505e-03  9.99720130e+01  1.20219479e+00], Reward: -1, Next state: [1.42788045e-02 9.97920961e+01 9.28309499e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-9.65255505e-03  9.99720130e+01  1.20219479e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [1.42788045e-02 9.97920961e+01 9.28309499e-01], Reward: 150.63575447598936, Next state: [8.28688210e-04 1.00316818e+02 7.88552409e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [1.42788045e-02 9.97920961e+01 9.28309499e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [8.28688210e-04 1.00316818e+02 7.88552409e-01], Reward: 0, Next state: [-3.03473893e-02  1.00098695e+02  1.14770682e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [8.28688210e-04 1.00316818e+02 7.88552409e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-3.03473893e-02  1.00098695e+02  1.14770682e+00], Reward: 294.92302156408954, Next state: [3.00732077e-02 1.00181746e+02 1.19518906e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-3.03473893e-02  1.00098695e+02  1.14770682e+00]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [3.00732077e-02 1.00181746e+02 1.19518906e+00], Reward: 0, Next state: [-2.66688836e-03  1.00405130e+02  1.17564564e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [3.00732077e-02 1.00181746e+02 1.19518906e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.66688836e-03  1.00405130e+02  1.17564564e+00], Reward: 23.183424208291115, Next state: [2.30112564e-03 1.00390358e+02 1.16783947e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.66688836e-03  1.00405130e+02  1.17564564e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [2.30112564e-03 1.00390358e+02 1.16783947e+00], Reward: 0, Next state: [-2.41408808e-02  9.98712888e+01  1.29066471e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.30112564e-03 1.00390358e+02 1.16783947e+00]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [-2.41408808e-02  9.98712888e+01  1.29066471e+00], Reward: 0, Next state: [6.07232660e-03 1.00085748e+02 1.03753450e+00], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-2.41408808e-02  9.98712888e+01  1.29066471e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [6.07232660e-03 1.00085748e+02 1.03753450e+00], Reward: -1, Next state: [2.93998425e-03 9.97686555e+01 9.42181986e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [6.07232660e-03 1.00085748e+02 1.03753450e+00]\n",
      "Target: nan, Q-value: nan, Action: 1, State: [2.93998425e-03 9.97686555e+01 9.42181986e-01], Reward: -1, Next state: [9.68055706e-03 9.96979553e+01 8.77037301e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [2.93998425e-03 9.97686555e+01 9.42181986e-01]\n",
      "Target: nan, Q-value: nan, Action: 0, State: [9.68055706e-03 9.96979553e+01 8.77037301e-01], Reward: 0, Next state: [-1.44323331e-02  9.92911023e+01  6.22964818e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [9.68055706e-03 9.96979553e+01 8.77037301e-01]\n",
      "Target: nan, Q-value: nan, Action: 2, State: [-1.44323331e-02  9.92911023e+01  6.22964818e-01], Reward: 0, Next state: [7.25954472e-03 9.95154588e+01 5.03409254e-01], Next Q-values: [np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "Error: nan, Weights: [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]], State: [-1.44323331e-02  9.92911023e+01  6.22964818e-01]\n",
      "Episode 0, Total Reward: 799.8946483377304, Epsilon: 0.9950\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = StockMarketEnv(prices[:3])\n",
    "\n",
    "# Train the agent\n",
    "state_size = 3  # 5 features: return, SMA, EMA, RSI, volatility\n",
    "action_size = 3  # Actions: Buy, Hold, Sell\n",
    "agent = LinearQTradingAgent(env, state_size, action_size)\n",
    "rewards = agent.train(episodes=1)\n",
    "\n",
    "print(agent.weights)\n",
    "\n",
    "# Plot training progress\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Q-Learning Trading Agent Training Progress\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -5.779960395108219, Epsilon: 0.0100\n",
      "Episode 100, Total Reward: -27.166271844590995, Epsilon: 0.0100\n",
      "Episode 200, Total Reward: 91.25584105472444, Epsilon: 0.0100\n",
      "Episode 300, Total Reward: 180.53086078649017, Epsilon: 0.0100\n",
      "Episode 400, Total Reward: -3, Epsilon: 0.0100\n",
      "Episode 500, Total Reward: -1, Epsilon: 0.0100\n",
      "Episode 600, Total Reward: -28.720169602461, Epsilon: 0.0100\n",
      "Episode 700, Total Reward: -77.67641137220369, Epsilon: 0.0100\n",
      "Episode 800, Total Reward: 52.887029580629076, Epsilon: 0.0100\n",
      "Episode 900, Total Reward: -25.775894969881506, Epsilon: 0.0100\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearQTradingAgent' object has no attribute 'q_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rewards \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtrain(episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_table\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot training progress\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(rewards)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearQTradingAgent' object has no attribute 'q_table'"
     ]
    }
   ],
   "source": [
    "rewards = agent.train(episodes=1000)\n",
    "\n",
    "print(agent.weights)\n",
    "\n",
    "# Plot training progress\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Q-Learning Trading Agent Training Progress\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(agent.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.32208128, 9.19562353, 7.35984651, 6.5657412 , 4.7785389 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = np.random.uniform(0, 10, 5) # Random walk stock prices\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.26961056,  98.80008711,  98.46228854,  98.32890243,\n",
       "        99.84787353,  97.6017017 ,  96.96319583,  96.03291171,\n",
       "        96.9149997 ,  97.08559153,  96.52210944,  95.90942777,\n",
       "        95.12978089,  96.49592941,  97.73475276,  98.68810329,\n",
       "       100.31714178,  99.59473505,  99.22707127,  99.97225519,\n",
       "        98.69719572,  97.03893435,  96.50913288,  96.48149357,\n",
       "        96.75264396,  96.94920933,  96.04972541,  95.84369672,\n",
       "        95.52744419,  97.42700735,  96.35506363,  95.36745711,\n",
       "        93.42797437,  93.62944789,  93.27287146,  93.18533665,\n",
       "        96.16527655,  97.91408933,  96.60557578,  94.83303921,\n",
       "        94.77428475,  95.41320164,  96.6017302 ,  96.33882051,\n",
       "        97.2983515 ,  98.45021407,  96.54274301,  96.99594312,\n",
       "        96.03593307,  96.99487635,  97.87126088, 100.78909253,\n",
       "       102.38511769, 102.6266674 , 102.2281297 , 101.59219094,\n",
       "       100.98973641, 102.21591556, 104.32518418, 103.68250376,\n",
       "       103.18522112, 102.64927253, 101.50512747, 101.62623196,\n",
       "       102.43223043, 103.02303378, 101.74607918, 102.17156556,\n",
       "       101.00145039, 100.90754604, 101.03607275, 101.43300695,\n",
       "        99.57348713, 100.04326565, 101.0698468 , 101.99695836,\n",
       "       102.96530526, 102.55274654, 103.76914079, 104.28314852,\n",
       "       105.85577073, 104.9980239 , 104.64308685, 103.98107943,\n",
       "       105.7628305 , 106.15313246, 107.85404515, 107.33385248,\n",
       "       107.44713603, 106.50022779, 105.55301934, 105.97235293,\n",
       "       106.70256787, 108.50763865, 107.94462196, 107.86155971,\n",
       "       107.25217561, 108.34827648, 109.43637095, 107.35519834,\n",
       "       106.78245983, 108.7265016 , 108.77221939, 110.61137741,\n",
       "       109.81608308, 108.47166256, 110.31444688, 109.35582096,\n",
       "       109.44604021, 110.44615253, 110.35969444, 110.75903858,\n",
       "       111.14855943, 112.57200698, 111.76353293, 111.50262149,\n",
       "       111.48573219, 112.08333319, 111.37774717, 109.96442231,\n",
       "       111.29870508, 110.35327963, 110.79649442, 109.88916626,\n",
       "       109.73683323, 109.60232002, 110.42450103, 111.16186074,\n",
       "       113.43678415, 113.08439196, 113.57832276, 114.51464531,\n",
       "       115.65822203, 116.67948986, 117.82830493, 117.50328876,\n",
       "       119.58741701, 118.00655441, 118.96605807, 118.73318914,\n",
       "       118.12692106, 117.37462505, 117.97450986, 117.35658151,\n",
       "       117.25138764, 117.59169063, 116.94163517, 117.33475909,\n",
       "       118.88342423, 118.47813729, 117.75599162, 118.21078761,\n",
       "       118.76748081, 119.6320303 , 119.95029541, 121.54038563,\n",
       "       122.81272124, 124.08059176, 125.02979041, 123.57467889,\n",
       "       122.77510065, 123.34516913, 123.61206849, 124.04157154,\n",
       "       124.74613461, 125.35982037, 126.37257978, 124.29029931,\n",
       "       124.68852163, 125.06865368, 124.66866118, 124.43046385,\n",
       "       124.77149998, 124.86207795, 125.31426994, 127.16573264,\n",
       "       126.45830616, 126.688244  , 127.28398143, 126.44516317,\n",
       "       127.12749463, 126.50183815, 127.30786262, 126.16022086,\n",
       "       128.36446324, 126.17382946, 126.40973645, 126.08230629,\n",
       "       127.16940808, 128.95861477, 128.89807849, 129.14890148,\n",
       "       128.66281401, 127.86998985, 127.58265428, 126.42150454,\n",
       "       126.76742396, 127.19197741, 127.1080333 , 127.77016425,\n",
       "       127.51506047, 127.89590861, 129.39499528, 130.66949153,\n",
       "       130.45700101, 129.9728055 , 130.92968499, 130.96792448,\n",
       "       129.27329415, 129.95309727, 128.965766  , 127.63963809,\n",
       "       127.75795241, 128.86495629, 129.27391267, 128.85039484,\n",
       "       130.59218227, 130.61348187, 130.43438612, 129.84567693,\n",
       "       130.21058188, 130.28532515, 130.35152673, 131.10316516,\n",
       "       130.64958655, 131.90379227, 131.56763204, 132.63941487,\n",
       "       131.38236936, 130.25792447, 128.91595076, 128.59027893,\n",
       "       128.65162879, 127.62837818, 127.60181352, 126.88909753,\n",
       "       125.50314634, 126.56188837, 125.35776287, 124.54516219,\n",
       "       125.41975247, 125.86695225, 126.60770179, 127.76107009,\n",
       "       126.94607503, 129.0072625 , 128.72700398, 127.19649779,\n",
       "       125.66164634, 125.24581248, 124.16883805, 124.07518655,\n",
       "       123.56668325, 124.59216152, 124.55086591, 124.30595802,\n",
       "       125.56202295, 125.17464476, 124.10431667, 126.3026749 ,\n",
       "       128.10363604, 128.96843117, 128.95627367, 129.14133075,\n",
       "       129.58131676, 130.48996737, 128.75040158, 129.76909199,\n",
       "       130.52596977, 130.0070843 , 128.76937516, 130.0820326 ,\n",
       "       131.03125075, 132.30801823, 133.7894003 , 134.39357727,\n",
       "       133.74483134, 134.82159646, 135.48109376, 137.58411538,\n",
       "       136.44008238, 136.11003424, 135.75472669, 135.31306966,\n",
       "       135.89701753, 135.83757596, 136.43489804, 136.3796787 ,\n",
       "       137.25126284, 137.56427758, 137.69601938, 139.05938745,\n",
       "       139.39662923, 139.09117434, 138.75802879, 136.71366728,\n",
       "       137.89658544, 138.34148371, 138.60611016, 139.04925436,\n",
       "       139.08947769, 137.96075057, 136.95351078, 135.61921824,\n",
       "       135.36125565, 135.118991  , 133.51566064, 133.71083912,\n",
       "       132.38091225, 131.48300289, 132.63844582, 132.80315962,\n",
       "       131.34017312, 132.31419282, 131.76058231, 132.50239217,\n",
       "       133.67804296, 133.49699272, 131.76416141, 131.9924194 ,\n",
       "       131.35415036, 129.79242451, 128.66477832, 128.09250315,\n",
       "       129.66355681, 128.27071925, 127.2365581 , 126.910952  ,\n",
       "       126.81331256, 126.6890369 , 126.83943262, 126.98800441,\n",
       "       126.56326554, 125.93235801, 126.55974012, 128.82414037,\n",
       "       128.81357942, 128.17649379, 129.12000492, 127.55521711,\n",
       "       128.52537966, 128.74028554, 128.34019828, 130.44494459,\n",
       "       130.26588785, 130.64046449, 130.85845395, 131.52221444,\n",
       "       132.92009011, 132.36778724, 135.05518156, 135.03861808,\n",
       "       135.41134761, 135.76512222, 134.98564064, 134.60776364,\n",
       "       134.56438604, 135.78700641, 135.52514171, 136.40216052,\n",
       "       136.56145135, 136.51812659, 137.72988178, 139.11644781,\n",
       "       136.16278776, 136.63293566, 137.24504758, 137.41600135,\n",
       "       136.17310179, 136.16867865, 137.07645815, 139.16113102,\n",
       "       139.59616194, 141.30883833, 142.41555565, 141.55128119,\n",
       "       140.06174597, 139.06452611, 138.6293366 , 137.27918504,\n",
       "       138.25884973, 137.66973532, 138.30764501, 140.17448681,\n",
       "       141.26004541, 140.02337013, 137.64659748, 134.63631433,\n",
       "       133.28045702, 133.78951502, 133.1657172 , 132.37701031,\n",
       "       132.26938461, 132.69127002, 132.26772116, 132.71360645,\n",
       "       133.15547949, 132.9849818 , 133.22418264, 133.64027079,\n",
       "       134.21151104, 135.93860984, 135.50314161, 135.652993  ,\n",
       "       136.46515231, 136.52191306, 135.69591345, 137.16264429,\n",
       "       137.30330966, 139.14620916, 139.71234843, 139.54987313,\n",
       "       139.721184  , 138.32597653, 137.90281639, 137.13934975,\n",
       "       138.2541035 , 137.80301711, 136.48562579, 136.33612681,\n",
       "       135.51178905, 134.20287625, 134.3946976 , 133.70526463,\n",
       "       132.73987713, 133.60082713, 133.26116028, 132.96702393,\n",
       "       131.4562984 , 131.24356669, 130.94957684, 129.54825178,\n",
       "       130.2431461 , 131.37342104, 132.01444885, 130.18229885,\n",
       "       129.30272403, 129.69492614, 129.76778951, 130.59191768,\n",
       "       130.25427585, 129.16498094, 129.83107568, 130.36110719,\n",
       "       130.2999602 , 130.60904578, 130.4062534 , 130.4731149 ,\n",
       "       130.31205369, 130.73080243, 130.81701359, 129.98473736,\n",
       "       129.91168464, 129.17596498, 129.23431814, 129.69468249,\n",
       "       129.28164746, 128.311126  , 127.70623777, 127.96447835,\n",
       "       127.90412032, 128.45730771, 127.56112358, 129.0799266 ,\n",
       "       127.97518582, 129.11717502, 129.22154001, 130.67292012,\n",
       "       130.48957985, 130.53337715, 129.29474463, 128.06032888,\n",
       "       128.82685918, 130.35402688, 130.83826596, 129.50229691,\n",
       "       129.29065875, 129.42096055, 128.51879273, 130.17247991,\n",
       "       131.17877764, 132.73699212, 133.28307887, 132.80904843,\n",
       "       132.60368975, 131.27206029, 129.7955633 , 131.90058126,\n",
       "       132.17644716, 133.21454034, 132.16838712, 132.87285909,\n",
       "       131.45371514, 130.14116266, 129.49544537, 130.37536531,\n",
       "       131.5292205 , 132.48696732, 133.34728322, 134.68908026])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.11090917 100.68725736  99.46731396  98.28597495]\n",
      "[100.67165666 100.11090917 100.68725736  99.46731396]\n",
      "[0.99442994 1.0057571  0.98788384 0.98812334]\n",
      "[[100.11090917 100.68725736  99.46731396  98.28597495]]\n",
      "((np.float64(100.1109091691082), np.float64(100.68725735641885), np.float64(99.46731395974697), np.float64(98.28597495302475)),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prices[1:])\n",
    "print(prices[:-1])\n",
    "print(prices[1:] / prices[:-1])\n",
    "\n",
    "print(np.array([prices[1:]]))\n",
    "tuplized = tuple(map(tuple, np.array([prices[1:]])))\n",
    "print(tuplized)\n",
    "\n",
    "test_dir = {\n",
    "    tuplized: 1,\n",
    "}\n",
    "\n",
    "test_dir[tuplized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Reward: 3977.3597257638103\n"
     ]
    }
   ],
   "source": [
    "def test_agent(agent, env):\n",
    "    \"\"\"Run a test episode with the trained agent\"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = max(agent._get_q_values(state), key=agent._get_q_values(state).get)\n",
    "        state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "# Test the trained agent\n",
    "final_reward = test_agent(agent, env)\n",
    "print(\"Final Test Reward:\", final_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
